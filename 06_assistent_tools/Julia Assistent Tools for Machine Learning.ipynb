{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "span.tt {\n",
       "    font-family: 'Lucida Sans Typewriter', 'Lucida Console', \n",
       "                  monaco, 'Bitstream Vera Sans Mono', monospace;\n",
       "    color: #ff6666;\n",
       "}\n",
       "\n",
       "div.method {\n",
       "    margin-bottom: 10px;\n",
       "}\n",
       "\n",
       "div.method_title {\n",
       "    padding: 4px 4px 4px 20px;\n",
       "    background-color:#696565; color:#ffa500;\n",
       "    border-left: 8px solid #fa8072;\n",
       "}\n",
       "\n",
       "div.method_body {\n",
       "    padding: 0px 20px 20px 20px;\n",
       "    border-left: 8px solid #fa8072;\n",
       "    background-color: #ffe4e1;\n",
       "}\n",
       "\n",
       "div.method_cell {}\n",
       "\n",
       "div.method_cell_title {\n",
       "    padding: 20px 0px 0px 0px;\n",
       "}\n",
       "\n",
       "div.method_cell_body {}\n",
       "\n",
       "\n",
       "h1.section {\n",
       "    border-bottom:5px solid #696565;\n",
       "}\n",
       "\n",
       "span.section_number {\n",
       "    background-color:#696565;\n",
       "    color:#ff6666;\n",
       "    padding:3px 5px 3px 5px;\n",
       "}\n",
       "\n",
       "span.section_title {\n",
       "    padding:5px 5px 0px 5px;\n",
       "    color:#ffa500;\n",
       "}\n",
       "\n",
       "</style>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h1 class=\"section\"><span class=\"section_title\">Julia Assistents Tools for Machine Learning</span></h1>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "style_css = \"\"\"\n",
    "<style>\n",
    "span.tt {\n",
    "    font-family: 'Lucida Sans Typewriter', 'Lucida Console', \n",
    "                  monaco, 'Bitstream Vera Sans Mono', monospace;\n",
    "    color: #ff6666;\n",
    "}\n",
    "\n",
    "div.method {\n",
    "    margin-bottom: 10px;\n",
    "}\n",
    "\n",
    "div.method_title {\n",
    "    padding: 4px 4px 4px 20px;\n",
    "    background-color:#696565; color:#ffa500;\n",
    "    border-left: 8px solid #fa8072;\n",
    "}\n",
    "\n",
    "div.method_body {\n",
    "    padding: 0px 20px 20px 20px;\n",
    "    border-left: 8px solid #fa8072;\n",
    "    background-color: #ffe4e1;\n",
    "}\n",
    "\n",
    "div.method_cell {}\n",
    "\n",
    "div.method_cell_title {\n",
    "    padding: 20px 0px 0px 0px;\n",
    "}\n",
    "\n",
    "div.method_cell_body {}\n",
    "\n",
    "\n",
    "h1.section {\n",
    "    border-bottom:5px solid #696565;\n",
    "}\n",
    "\n",
    "span.section_number {\n",
    "    background-color:#696565;\n",
    "    color:#ff6666;\n",
    "    padding:3px 5px 3px 5px;\n",
    "}\n",
    "\n",
    "span.section_title {\n",
    "    padding:5px 5px 0px 5px;\n",
    "    color:#ffa500;\n",
    "}\n",
    "\n",
    "</style>\n",
    "\"\"\"\n",
    "display(\"text/html\", style_css)\n",
    "\n",
    "function render_doc(method_signature, description, arguments, outputs)\n",
    "    arguments_html       = field_list_to_html(arguments)\n",
    "    outputs_html         = field_list_to_html(outputs)\n",
    "    html_method_template = \"\"\"\n",
    "    <div class=\"method\">\n",
    "        <div class=\"method_title\"><span class=\"tt\">Method: </span><b>$method_signature</b></div>\n",
    "            <div class=\"method_body\">\n",
    "                <div class=\"method_cell\">\n",
    "                    <div class=\"method_cell_title\"><span class=\"tt\"><b>Description</b></span></div>\n",
    "                    <div class=\"method_cell_body\">\n",
    "                        <span class=\"tt\">$description.</span>\n",
    "                    </div>\n",
    "                </div>\n",
    "                <div class=\"method_cell\">\n",
    "                    <div class=\"method_cell_title\"><span class=\"tt\"><b>Arguments</b></span></div>\n",
    "                    <div class=\"method_cell_body\">\n",
    "                        <ul>\n",
    "                            $arguments_html\n",
    "                        </ul>\n",
    "                    </div>\n",
    "                </div>\n",
    "                <div class=\"method_cell\">\n",
    "                    <div class=\"method_cell_title\"><span class=\"tt\"><b>Outputs</b></span></div>\n",
    "                    <div class=\"method_cell_body\">\n",
    "                        <ul>\n",
    "                            $outputs_html\n",
    "                        </ul>\n",
    "                    </div>\n",
    "                </div>\n",
    "            </div>\n",
    "        </div>\n",
    "    <div/>\n",
    "    \"\"\"\n",
    "    return display(\"text/html\", html_method_template)\n",
    "end\n",
    "\n",
    "function field_list_to_html(list)\n",
    "    length(list) == 0 && return \"<span class=\\\"tt\\\">None.</span>\"\n",
    "    html = \"\"\n",
    "    for (field_name, field_type, field_description) in list\n",
    "        html *= \"<li><span class=\\\"tt\\\">$field_name, <b>$field_type</b>: \"\n",
    "        html *= \"$field_description.</span></li>\\n\"\n",
    "    end\n",
    "    return html\n",
    "end\n",
    "\n",
    "function render_section(section_number, subsection_number, title)\n",
    "    html = \"\"\"<h1 class=\"section\">\"\"\"\n",
    "    if length(section_number) > 0\n",
    "        html *= \"\"\"<span class=\"section_number\">$section_number.$subsection_number</span>\"\"\" \n",
    "    end\n",
    "    html *= \"\"\"<span class=\"section_title\">$title</span></h1>\"\"\"\n",
    "    return display(\"text/html\", html)\n",
    "end\n",
    "render_section(\"\", \"\", \"Julia Assistents Tools for Machine Learning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Author: [Oliveira, D. M.](http://br.linkedin.com/in/dmztheone) - [GitHub](http://www.github.com/dmoliveira)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "render_section(\"\", \"\", \"Introduction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a proper introduction... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "render_section(\"01\", \"\", \"Import Packages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Base.String is deprecated, use AbstractString instead.\n",
      "  likely near /Users/diego/.julia/v0.4/MLBase/src/modeltune.jl:5\n",
      "WARNING: Base.String is deprecated, use AbstractString instead.\n",
      "  likely near /Users/diego/.julia/v0.4/MLBase/src/modeltune.jl:5\n",
      "WARNING: Base.String is deprecated, use AbstractString instead.\n",
      "  likely near /Users/diego/.julia/v0.4/MLBase/src/modeltune.jl:5\n",
      "WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.\n",
      "  likely near /Users/diego/.julia/v0.4/MLBase/src/deprecated/datapre.jl:104\n",
      "WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.\n",
      "  likely near /Users/diego/.julia/v0.4/MLBase/src/deprecated/datapre.jl:105\n",
      "WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.\n",
      "  likely near /Users/diego/.julia/v0.4/MLBase/src/deprecated/datapre.jl:163\n",
      "WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.\n",
      "  likely near /Users/diego/.julia/v0.4/MLBase/src/deprecated/datapre.jl:163\n",
      "WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.\n",
      "  likely near /Users/diego/.julia/v0.4/MLBase/src/deprecated/datapre.jl:163\n"
     ]
    }
   ],
   "source": [
    "using Base.Test\n",
    "using RegERMs\n",
    "using Distances\n",
    "using DataFrames\n",
    "using DataStructures\n",
    "using DecisionTree\n",
    "using Iterators\n",
    "using MLBase\n",
    "using GLM\n",
    "using GLMNet\n",
    "using XGBoost\n",
    "using GZip\n",
    "using PyCall\n",
    "using Gadfly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@pyimport sklearn.linear_model as sklm\n",
    "@pyimport sklearn.svm as svm\n",
    "@pyimport sklearn.neighbors as skknn\n",
    "@pyimport sklearn.naive_bayes as naive_bayes\n",
    "@pyimport sklearn.tree as tree\n",
    "@pyimport sklearn.ensemble as ensemble\n",
    "@pyimport scipy.sparse as scipy_sparse\n",
    "@pyimport fastFM.als as ffm_als\n",
    "@pyimport fastFM.sgd as ffm_sgd\n",
    "@pyimport fastFM.mcmc as ffm_mcmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "render_section(\"02\", \"\", \"HTML Assistent Tools\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HTML Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "html = \"\"\"\n",
    "<script>\n",
    "    code_show=true; \n",
    "    function code_toggle() {\n",
    "     if (code_show){\n",
    "     \\$('div.input').hide();\n",
    "     } else {\n",
    "     \\$('div.input').show();\n",
    "     }\n",
    "     code_show = !code_show\n",
    "    } \n",
    "    \\$( document ).ready(code_toggle);\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\">\n",
    "    <input type=\"submit\" value=\"Click here to toggle on/off the raw code.\">\n",
    "</form>\"\"\"\n",
    "display(\"text/html\", html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "render_section(\"02\", \"\", \"Summary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Functions Transform Data**\n",
    "    - binarize(value::Number, lower=0::Number, upper=1::Number; threshold=.5::Number)\n",
    "    - binarize(values::Vector{Number}, lower=0::Number, upper=1::Number; threshold=.5::Number)\n",
    "    - transform_elements!{T<:Number}(vector::Vector{T}, func, args; kwargs...)\n",
    "    - transform_elements!{T<:Number}(matrix::Array{T,2}, func, args; kwargs...)\n",
    "- **Functions for Missing Values**\n",
    "    - get_default_values(df, features)\n",
    "    - apply_default_values!(df, default_values)\n",
    "- **Functions for Label Encoding**\n",
    "    - get_label_encoding(df, features)\n",
    "    - apply_encoding!(df, encoding)\n",
    "- **Functions Features Expansion**\n",
    "    - get_all_values(df, features)\n",
    "    - apply_one_hot_encoding!(df, features, all_values)\n",
    "    - apply_interval_features!(df, features, interval_values)\n",
    "- **Functions Feature Space Vector Transformation**\n",
    "    - gen_feature_space(features, separator='__')\n",
    "    - expand_feature_space(key_features, feature_space, features)\n",
    "- **Functions Extract Date and Time**\n",
    "    - extract_date_features(string_date)\n",
    "    - extract_time_features(string_time_hhmmss)\n",
    "- **Functions Extract Age Features**\n",
    "    - extract_age_features(age)\n",
    "- **Functions Export CSV/TSV**\n",
    "    - export_csv(df, file_path)\n",
    "    - export_tsv(df, file_path)\n",
    "    - export_gz(data, file_path)\n",
    "- **Functions Split Train/Validation Sets**\n",
    "    - split_train_val (df; train_size=.85, random_state=1)\n",
    "    - gen_train_val (train, features, label, train_size=.85, random_state=1)\n",
    "- **Functions XGBoost Auxiliary Tools**\n",
    "    - gen_dtrain(train, features, label, train_size=.85, random_state=1)\n",
    "- **Functions GLM Auxiliary Tools**\n",
    "    - gen_formula(features, label)\n",
    "    - gen_formulas(features, label)\n",
    "    - gen_formulas(features, feature_space, label, min_vars_formula, max_vars_formula)\n",
    "    - gen_glm(train, formulas, family=Binomial(), link=LogitLink())\n",
    "    - train_glmnet(X, y, family=Normal(), alpha=1)\n",
    "    - predict(model::GLMNet.GLMNetPath, X)\n",
    "- **Functions Decision Trees, Random Forests and Tree related**\n",
    "    - train_decision_tree(train_x, train_y; leaves_purity=.9)\n",
    "    - train_random_forest(train_x, train_y; random_features=2, num_trees=10, portion_samples=.5)\n",
    "    - train_adaptive_boosted_trees(train_x, train_y; num_iteration=7)\n",
    "    - predict(model, x)\n",
    "    - predict(model, x)\n",
    "    - predict(model, coeffs, x)\n",
    "- **Functions Fast Factorization Machines**\n",
    "    - train_fmregression(X, y; n_iter=1000, init_stdev=.1, rank=2, l2_reg_w=.1, l2_reg_V=.5)\n",
    "    - train_fmclassification_sgd(X, y; n_iter=1000, init_stdev=.1, rank=2, l2_reg_w=0, l2_reg_V=0, step_size=.1)\n",
    "    - train_predict_fmclassification_mcmc(X, y, Xpred; n_iter=1000, rank=2, init_stdev=.1)\n",
    "    - predict(::Type{FastFMModel}, model, X)\n",
    "- **Functions Empirical Risk Minimization Models**\n",
    "    - train_svm_rerm(X, y; optimizer=:l_bfgs, λ=1.0)\n",
    "    - train_ridge_regression_rerm(X, y; optimizer=:l_bfgs, λ=1.0)\n",
    "    - train_logistic_regression_rerm(X, y; optimizer=:l_bfgs, λ=1.0)\n",
    "    - train_multi_logistic_regression_rerm(X, y; optimizer=:l_bfgs, λ=1.0)\n",
    "    - predict{T<:RegERMs.RegressionModel}(model::T, X)\n",
    "- **Functions Scikit Learning**\n",
    "    - train_scikit_model(model, train_x, train_y)\n",
    "    - train_scikit_models(models, train_x, train_y)\n",
    "    - predict_scikit_model(model, X)\n",
    "    - predict_scikit_models(models, X)\n",
    "- **Functions Evaluation Metrics**\n",
    "    - eval_rmse(y, yhat)\n",
    "    - eval_precision(y, yhat)\n",
    "- **Functions Vowpal Wabbit**\n",
    "    - generate_vw_file(df, feature_space_indexes, feature_space_names)\n",
    "    - train_vw_binary_classifier(vw_file_path_gzip, output_model_file_path, passes=1, quad_features=[], cubic_features=[], l1=0, l2=0, decay_learning_rate=1, initial_t=0, power_t=.5, learning_rate=.5)\n",
    "    - predict_vw(model_file_path, predict_file_path)\n",
    "- **Functions Useful Dataframe Templates**\n",
    "    - gen_dataframe_results(models_name, results, groups_name)\n",
    "- **Functions Useful Plots**\n",
    "    - plot_series(title, dataframe, x, y, group; width=1000px, height=550px)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data For Simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = DataFrame(FeatureA_1=rand(5), FeatureA_2=rand(5), FeatureA_3=rand(5),\n",
    "               FeatureB=rand(5), FeatureC_1=rand(5), FeatureC_2=rand(5),\n",
    "               Y=rand([-1, 1], 5))\n",
    "features = setdiff(names(df), [:Y])\n",
    "label = :Y\n",
    "X = Matrix(df[:, features])\n",
    "y = Vector(df[:, label]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "render_section(\"0X\", \"\", \"Functions: Filter Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: Create proper filter functions\n",
    "# create_filter_startwith(dataframe::DataFrame, column::Symbol, values) = \n",
    "# filter_no_glmnets = Vector{Bool}([!startswith(n, \"lasso_\") && !startswith(n, \"glmnets_\") &&\n",
    "#                                  !startswith(n, \"ridges_\") for n in map(string, results[:Model])])\n",
    "# filter_lasso   = Vector{Bool}([startswith(n, \"lasso_\") for n in map(string, results[:Model])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "render_section(\"04\", \"\", \"Functions: Transform Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "render_doc(\"binarize (value, lower=0, upper=1; threshold=.5)\",\n",
    "           \"Truncate data in binary form. If data below threshold set lower, otherwise set upper\",\n",
    "           [(\"value\", \"Number\", \"Value to truncate in binary lower or upper\"),\n",
    "            (\"lower\", \"Number\", \"Lower value to set (Default=0)\"),\n",
    "            (\"upper\", \"Number\", \"Upper value to set (Default=1)\"),\n",
    "            (\"threshold\", \"Number\", \"\"\"The limiar to set lower or upper.\n",
    "              If value < t then set lower, otherwise if value >= t set upper\"\"\")],\n",
    "           [(\"_\", \"Number\", \"Results truncated in binary form\")])\n",
    "    \n",
    "render_doc(\"binarize (values, lower=0, upper=1; threshold=.5)\",\n",
    "           \"Truncate data in binary form. If data below threshold set lower, otherwise set upper\",\n",
    "           [(\"values\", \"Vector{Number}\", \"Values to truncate in binary lower or upper\"),\n",
    "            (\"lower\", \"Number\", \"Lower value to set (Default=0)\"),\n",
    "            (\"upper\", \"Number\", \"Upper value to set (Default=1)\"),\n",
    "            (\"threshold\", \"Number\", \"\"\"The limiar to set lower or upper.\n",
    "              If value < t then set lower, otherwise if value >= t set upper\"\"\")],\n",
    "           [(\"_\", \"Array{Number,1}\", \"Results truncated in binary form\")])\n",
    "\n",
    "render_doc(\"transform_elements!{T<:Number}(vector::Vector{T}, func, args; kwargs...)\",\n",
    "           \"Tranform each element of a vector by a function <b>func</b>\",\n",
    "         [(\"vector\", \"Vector{Number}\", \"Vector that will be transformed\"),\n",
    "          (\"func\", \"Function\", \"Function to transform each element of the vector\"),\n",
    "          (\"args\", \"Tuple\", \"Extra arguments passed by vargs\"),\n",
    "          (\"kwargs\", \"Dict\", \"Extra kwargs arguments\")],\n",
    "         [(\"vector\", \"Vector{Number}\", \"Vector transformed\")])\n",
    "\n",
    "render_doc(\"transform_elements!{T<:Number}(vector::Array{T,2}, func, args; kwargs...)\",\n",
    "           \"Tranform each element of a matrix by a function <b>func</b>\",\n",
    "         [(\"vector\", \"Array{Number,2}\", \"Matrix that will be transformed\"),\n",
    "          (\"func\", \"Function\", \"Function to transform each element of the matrix\"),\n",
    "          (\"args\", \"Tuple\", \"Extra arguments passed by vargs\"),\n",
    "          (\"kwargs\", \"Dict\", \"Extra kwargs arguments\")],\n",
    "         [(\"matrix\", \"Array{Number,2}\", \"Matrix transformed\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "binarize{T<:Number}(value::T, lower=0, upper=1; threshold=.5) = value < threshold? lower : upper\n",
    "function binarize{T<:Number}(values::Vector{T}, lower=0, upper=1; threshold=.5)\n",
    "    return [value < threshold? lower : upper for value in values]\n",
    "end\n",
    "\n",
    "transform_elements!{T<:Number}(vector::Vector{T}, func, args) = [func(v, args...) for v in vector]\n",
    "transform_elements!{T<:Number}(vector::Vector{T}, func; kwargs...) = [func(v; kwargs...) for v in vector]\n",
    "transform_elements!{T<:Number}(vector::Vector{T}, func, args; kwargs...) = [func(v, args...; kwargs...) for v in vector]\n",
    "\n",
    "function transform_elements!{T<:Number}(matrix::Array{T,2}, func, args; kwargs...)\n",
    "    for i=1:size(matrix,1), j=1:size(matrix,2)\n",
    "        matrix[i, j] = func(matrix[i, j], args...; kwargs...)\n",
    "    end\n",
    "    return matrix\n",
    "end\n",
    "\n",
    "function transform_elements!{T<:Number}(matrix::Array{T,2}, func, args)\n",
    "    for i=1:size(matrix,1), j=1:size(matrix,2)\n",
    "        matrix[i, j] = func(matrix[i, j], args...)\n",
    "    end\n",
    "    return matrix\n",
    "end\n",
    "\n",
    "function transform_elements!{T<:Number}(matrix::Array{T,2}, func; kwargs...)\n",
    "    for i=1:size(matrix,1), j=1:size(matrix,2)\n",
    "        matrix[i, j] = func(matrix[i, j]; kwargs...)\n",
    "    end\n",
    "    return matrix\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Tranform Elements Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "srand(1)\n",
    "trans(v, p=2; div=1) = v^p+div\n",
    "matrix = rand([1:10], 2,3)\n",
    "transform_elements!(matrix, trans, 2; div=2)\n",
    "results = [83 102 18; 51 102 3]\n",
    "@test matrix == results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "render_section(\"04\", \"\", \"Functions: Missing Values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "render_doc(\"get_default_values (df, features)\", \n",
    "           \"\"\"Calculates the mode for all features informed. \n",
    "              Usually it is used to replace missing data\"\"\", \n",
    "           [(\"df\", \"DataFrame\", \"Data used to calculate modes by column\"),\n",
    "            (\"features\", \"Array{Symbol,1}\", \"Column names that will be considered\")],\n",
    "           [(\"default_values\", \"Dict\", \"Dictionary with the default values\")])\n",
    "\n",
    "render_doc(\"apply_default_values! (df, default_values)\",\n",
    "           \"\"\"Apply a dictionary of default values to missing values (NAs) of the\n",
    "              given dataframe. Only keys identified as column will be used\"\"\",\n",
    "          [(\"df\", \"DataFrame\", \"Data that will be used to replace NAs to default values\"),\n",
    "           (\"default_values\", \"Dict\", \"Dictionary with features/default values\")],\n",
    "          [(\"df\", \"DataFrame\", \"Original dataframe with NAs replaced by default values\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function get_default_values(df, features)\n",
    "    default_values = Dict()\n",
    "    for feature in features\n",
    "        default_value = mode(dropna(df[feature]))\n",
    "        default_values[feature] = default_value\n",
    "    end\n",
    "    return default_values\n",
    "end\n",
    "\n",
    "function apply_default_values!(df, default_values)\n",
    "    for feature in keys(default_values)\n",
    "        df[isna(df[feature]), feature] = default_values[feature]\n",
    "    end\n",
    "    return df\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "render_section(\"05\", \"\", \"Functions: Label Encoding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "render_doc(\"get_label_encoding (df, features)\",\n",
    "           \"Get label encoding for features of a given dataframe\",\n",
    "           [(\"df\", \"DataFrame\", \"Data that will be used to create label encoding\"), \n",
    "            (\"features\", \"Array{Symbol,1}\", \"Features that will be created label encoding\")],\n",
    "            [(\"_\", \"Dict\", \"A dictionary with the encoding for each feature informed\")])\n",
    "\n",
    "render_doc(\"apply_encoding! (df, encoding)\",\n",
    "           \"Apply encoding to a given dataframe\",\n",
    "           [(\"df\", \"DataFrame\", \"Dataframe that will be encoded\"),\n",
    "            (\"encoding\", \"Dict\", \"A dictionary with the feature/encoding data\")],\n",
    "           [(\"df\", \"DataFrame\", \"Dataframe with encoded columns\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_label_encoding(df, features) = Dict([f => labelmap(dropna(df[f])) for f in features])\n",
    "\n",
    "function apply_encoding!(df, encoding)\n",
    "    for feature in keys(encoding)\n",
    "        df[feature] = labelencode(encoding[feature], df[feature])\n",
    "    end\n",
    "    return df\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "render_section(\"06\", \"\", \"Functions: Feature Transformation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "render_section(\"06\", \"01\", \"Feature Transformation: One Hot Encoding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "render_doc(\"get_all_values (df, features)\",\n",
    "           \"Get all unique values from a given dataframe\",\n",
    "           [(\"df\", \"DataFrame\", \"Dataframe used to extract unique values\"),\n",
    "            (\"features\", \"Array{Symbol,1}\", \"Features that will be extract unique values\"),\n",
    "            (\"all_values\", \"Dict\", \"\")],\n",
    "           [(\"_\", \"Dict\", \"A dictionary with unique values for each feature informed\")])\n",
    "\n",
    "render_doc(\"apply_one_hot_encoding! (df, features, all_values)\",\n",
    "           \"\"\"Transform for each informed feature in N binary features\n",
    "              where is equal 1 when found the value in the new binary vector.\n",
    "              * The original columns will be deleted. See more about this\n",
    "              <a src=\"http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">\n",
    "              subject</a>\"\"\",\n",
    "          [(\"df\", \"DataFrame\", \"Dataframe used to expand with one hot encoding\"),\n",
    "           (\"features\", \"Array{Symbol,1}\", \"Features to expand with one hot encoding\")],\n",
    "          [(\"df\", \"DataFrame\", \"Dataframe with columns expanded by one hot encoding\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_all_values(df, features) = Dict([f => Set(dropna(df[f])) for f in features])\n",
    "\n",
    "function apply_one_hot_encoding!(df, features, all_values)\n",
    "    feature_names = get_categorical_features_names(features, all_values)\n",
    "    categorical_feature_matrix = get_categorical_feature_matrix(df, features, all_values)\n",
    "    apply_categorical_feature_matrix!(df, feature_names, categorical_feature_matrix)\n",
    "    remove_features!(df, features)\n",
    "    return df\n",
    "end\n",
    "\n",
    "function get_categorical_features_names(features, all_values)\n",
    "    feature_names = []\n",
    "    for feature in features\n",
    "        for value in all_values[feature]\n",
    "            push!(feature_names, symbol(feature, \"_\", value))\n",
    "        end\n",
    "    end\n",
    "    return feature_names\n",
    "end\n",
    "\n",
    "function get_categorical_feature_matrix(df, features, all_values)\n",
    "    new_feature_matrix = []\n",
    "    nrows = size(df, 1)\n",
    "    for i=1:nrows, f=1:length(features)\n",
    "        i % 1000 == 0 && f == 1 &&  println(\"\\tProcessed Categorical Feature $i/$nrows.\")\n",
    "        push!(new_feature_matrix, \n",
    "              to_cat_vector(all_values[features[f]], df[i, features[f]])\n",
    "        )\n",
    "    end\n",
    "    new_feature_matrix = vcat(new_feature_matrix...)\n",
    "    ncols = sum([length(all_values[feature]) for feature in features])\n",
    "    new_feature_matrix = reshape(new_feature_matrix, ncols, nrows)'\n",
    "    return new_feature_matrix\n",
    "end\n",
    "\n",
    "function apply_categorical_feature_matrix!(df, feature_names, feature_matrix)\n",
    "    nfeatures = length(feature_names)\n",
    "    for i=1:nfeatures\n",
    "        df[feature_names[i]] = feature_matrix[:, i]\n",
    "    end\n",
    "    return df\n",
    "end\n",
    "\n",
    "function remove_features!(df, feature_names)\n",
    "    for feature in feature_names\n",
    "        delete!(df, feature)\n",
    "    end\n",
    "    return df\n",
    "end\n",
    "\n",
    "to_cat_vector(all_values, actual_value) = [Int(value == actual_value) for value in all_values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "render_section(\"06\", \"02\", \"Features Transformation: Interval Features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "render_doc(\"apply_interval_features! (df, features, interval_values)\",\n",
    "           \"\"\"Transform for each informed feature in N interval features given by\n",
    "              a dictionary. The feature vector iterates throught each interval\n",
    "              using the function [ei < X < ei+1], e1 >= X and eEnd <= X\"\"\",\n",
    "          [(\"df\", \"DataFrame\", \"Dataframe used to expand with one hot encoding\"),\n",
    "           (\"features\", \"Array{Symbol,1}\", \"Features to expand with one hot encoding\"),\n",
    "           (\"interval_values\", \"Dict\", \"\"\"A dictionary where the key is the feature name\n",
    "             and the value is a list with the valid intervals\"\"\")],\n",
    "          [(\"df\", \"DataFrame\", \"Dataframe with columns expanded by interval features\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function apply_interval_features!(df, features, interval_values)\n",
    "    feature_names = get_interval_features_names(features, interval_values)\n",
    "    interval_feature_matrix = get_interval_feature_matrix(df, features, interval_values)\n",
    "    apply_categorical_feature_matrix!(df, feature_names, interval_feature_matrix)\n",
    "    remove_features!(df, features)\n",
    "    return df\n",
    "end\n",
    "\n",
    "function get_interval_features_names(features, interval_values)\n",
    "    feature_names = []\n",
    "    for feature in features\n",
    "        intervals = interval_values[feature]\n",
    "        for i=1:length(intervals) - 1\n",
    "            push!(feature_names, symbol(feature, \"_e\", \n",
    "                  intervals[i], \"x\", intervals[i+1]))\n",
    "        end\n",
    "        push!(feature_names, symbol(feature, \"_\", intervals[1]))\n",
    "        push!(feature_names, symbol(feature, \"_e\", intervals[end]))\n",
    "    end\n",
    "    return feature_names\n",
    "end\n",
    "\n",
    "function get_interval_feature_matrix(df, features, interval_values)\n",
    "    new_feature_matrix = []\n",
    "    nrows = size(df, 1)\n",
    "    for i=1:nrows, f=1:length(features)\n",
    "        i % 1000 == 0 && f == 1 &&  println(\"\\tProcessed Categorical Feature $i/$nrows.\")\n",
    "        push!(new_feature_matrix, \n",
    "              to_interval_vector(interval_values[features[f]], df[i, features[f]])\n",
    "        )\n",
    "    end\n",
    "    new_feature_matrix = vcat(new_feature_matrix...)\n",
    "    ncols = sum([length(interval_values[feature]) + 1 for feature in features])\n",
    "    new_feature_matrix = reshape(new_feature_matrix, ncols, nrows)'\n",
    "    return new_feature_matrix\n",
    "end\n",
    "\n",
    "function to_interval_vector(interval_values, actual_value)\n",
    "    features = [Int(interval_values[i] <= actual_value < interval_values[i+1])\n",
    "                    for i=1:length(interval_values) - 1]\n",
    "    push!(features, Int(actual_value < interval_values[1]))\n",
    "    push!(features, Int(interval_values[end] <= actual_value))\n",
    "    return features\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "render_section(\"06\", \"03\", \"Feature Transformation: Feature Space\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "render_doc(\"gen_feature_space (features, separator='_')\",\n",
    "           \"\"\"Generate feature space. It groups feature that have the same prefix.\n",
    "              It can receives a separator to break feature name. For example, if\n",
    "              exists FeatureA_1 FeatureA_2 and FeatureB, when passed through\n",
    "              this method we got as feature space FeatureA and Feature B with\n",
    "              its respective indices\"\"\",\n",
    "           [(\"features\", \"Array{Symbol,1}\", \"Features to be analyzed\"),\n",
    "            (\"separator\", \"Char\", \"Separator used to get the feature prefix\")],\n",
    "           [(\"feature_space\", \"OrderedDict\", \"Ordered dict with key as key feature\"*\n",
    "             \" and value as tuple with start and end index\")])\n",
    "\n",
    "render_doc(\"expand_feature_space (key_features, feature_space, features)\",\n",
    "           \"\"\" Expand feature space based on key features.\"\"\",\n",
    "           [(\"key_features\", \"Array{Symbol,1}\", \"Key features to expand feature_space\"),\n",
    "            (\"feature_space\", \"Dict\", \"Feature space dictionary with all key_features and indices\"),\n",
    "            (\"features\", \"Array{Symbol,1}\", \"All features\")],\n",
    "           [(\"expanded_features\", \"Array{Symbol,1}\", \"All features derived from key_features\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function gen_feature_space(features, separator='_')\n",
    "    prefix_feature = [Symbol(split(string(feature), separator)[1]) for feature in features]\n",
    "    key_feature    = Set(prefix_feature)\n",
    "    feature_space  = [(key, (findfirst(prefix_feature, key), findlast(prefix_feature, key))) for key in key_feature]\n",
    "    feature_space  = OrderedDict(sort(feature_space, by = v -> v[2]))\n",
    "    return feature_space\n",
    "end\n",
    "\n",
    "function expand_feature_space(key_features, feature_space, features)\n",
    "    expanded_features = Symbol[]\n",
    "    for key in key_features\n",
    "        start_index, end_index = feature_space[key]\n",
    "        append!(expanded_features, vcat(features[start_index : end_index]...))\n",
    "    end\n",
    "    return expanded_features\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Feature Space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scenario 01: Feature Space Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_space = gen_feature_space(features)\n",
    "result = OrderedDict([(:FeatureA, (1,3)), (:FeatureB, (4,4)), (:FeatureC, (5,6))])\n",
    "@test feature_space == result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scenario 02: Expand Feature Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result1 = [:FeatureA_1, :FeatureA_2, :FeatureA_3]\n",
    "result2 = [:FeatureA_1, :FeatureA_2, :FeatureA_3, :FeatureC_1, :FeatureC_2]\n",
    "result3 = [:FeatureA_1, :FeatureA_2, :FeatureA_3, :FeatureB]\n",
    "result4 = [:FeatureB]\n",
    "result5 = [:FeatureB, :FeatureC_1, :FeatureC_2]\n",
    "result6 = [:FeatureC_1, :FeatureC_2]\n",
    "@test expand_feature_space([:FeatureA], feature_space, features) == result1\n",
    "@test expand_feature_space([:FeatureA, :FeatureC], feature_space, features) == result2\n",
    "@test expand_feature_space([:FeatureA, :FeatureB], feature_space, features) == result3\n",
    "@test expand_feature_space([:FeatureB], feature_space, features) == result4\n",
    "@test expand_feature_space([:FeatureB, :FeatureC], feature_space, features) == result5\n",
    "@test expand_feature_space([:FeatureC], feature_space, features) == result6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "render_section(\"07\", \"01\", \"Features: Extract Date Features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "render_doc(\"extract_date_features (string_date)\",\n",
    "           \"Create feature vector from a raw string date\",\n",
    "         [(\"string_date\", \"AbstractString\", \"A string date in format YYYY-mm-dd\")],\n",
    "           [(\"_\", \"Array{Int,1}\", \"Feature vector of date\")])\n",
    "\n",
    "render_doc(\"extract_time_features(string_time_hhmmss)\",\n",
    "           \"Create feature vector from a raw string time\",\n",
    "           [(\"string_time_hhmmss\", \"AbstractString\", \"A string time in format HHMMSS\")],\n",
    "           [(\"_\", \"Array{Int,1}\", \"Feature vector of time\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DATE_FEATURES_NAMES = [:is_sunday, :is_monday, :is_tuesday, :is_wednesday, :is_thursday, \n",
    "                       :is_friday, :is_saturday, :is_weekday, :is_weekend, :is_middle_week,\n",
    "                       :is_january, :is_february, :is_march, :is_april, :is_may, :is_june,\n",
    "                       :is_july, :is_august, :is_september, :is_october, :is_november, \n",
    "                       :is_december, :is_first_quarter_year, :is_second_quarter_year, \n",
    "                       :is_third_quarter_year, :is_forth_quarter_year, :is_first_trimester_year, \n",
    "                       :is_second_trimester_year, :is_third_trimester_year, :is_first_half_year, \n",
    "                       :is_second_half_year]\n",
    "\n",
    "HOUR_FEATURES_NAMES = [:is_morning, :is_afternoon, :is_evenning, :is_night, :is_late_night, \n",
    "                       :is_midday, :is_launch_time, :is_end_work_day]\n",
    "\n",
    "function extract_date_features(string_date)\n",
    "    \n",
    "    date = Date(string_date)\n",
    "    \n",
    "    dayofweek       = Dates.dayofweek(date)    \n",
    "    is_sunday       = Dates.Sunday == dayofweek? 1 : 0\n",
    "    is_monday       = Dates.Monday == dayofweek? 1 : 0\n",
    "    is_tuesday      = Dates.Tuesday == dayofweek? 1 : 0\n",
    "    is_wednesday    = Dates.Wednesday == dayofweek? 1 : 0\n",
    "    is_thursday     = Dates.Thursday == dayofweek? 1 : 0\n",
    "    is_friday       = Dates.Friday == dayofweek? 1 : 0\n",
    "    is_saturday     = Dates.Saturday == dayofweek? 1 : 0\n",
    "    is_weekday      = Dates.Monday <= dayofweek <= Dates.Friday? 1 : 0\n",
    "    is_weekend      = Dates.Saturday <= dayofweek <= Dates.Sunday? 1 : 0\n",
    "    is_middle_week  = Dates.Tuesday <= dayofweek <= Dates.Thursday? 1 : 0\n",
    "    \n",
    "    month = Dates.month(date)\n",
    "    is_january               = Dates.January == month? 1 : 0\n",
    "    is_february              = Dates.February == month? 1 : 0\n",
    "    is_march                 = Dates.March == month? 1 : 0\n",
    "    is_april                 = Dates.April == month? 1 : 0\n",
    "    is_may                   = Dates.May == month? 1 : 0\n",
    "    is_june                  = Dates.June == month? 1 : 0\n",
    "    is_july                  = Dates.July == month? 1 : 0\n",
    "    is_august                = Dates.August == month? 1 : 0\n",
    "    is_september             = Dates.September == month? 1 : 0\n",
    "    is_october               = Dates.October == month? 1 : 0\n",
    "    is_november              = Dates.November == month? 1 : 0\n",
    "    is_december              = Dates.December == month? 1 : 0\n",
    "    is_first_quarter_year    = month < 4? 1 : 0\n",
    "    is_second_quarter_year   = 4 <= month < 7? 1 : 0\n",
    "    is_third_quarter_year    = 7 <= month < 10? 1 : 0\n",
    "    is_forth_quarter_year    = month >= 10? 1 : 0\n",
    "    is_first_trimester_year  = month <= 4? 1 : 0\n",
    "    is_second_trimester_year = 4 < month <= 8? 1 : 0\n",
    "    is_third_trimester_year  = month > 8? 1 : 0\n",
    "    is_first_half_year       = month <= 6? 1 : 0\n",
    "    is_second_half_year      = month > 6? 1 : 0\n",
    "    \n",
    "    return [is_sunday, is_monday, is_tuesday, is_wednesday, is_thursday, \n",
    "            is_friday, is_saturday, is_weekday, is_weekend, is_middle_week,\n",
    "            is_january, is_february, is_march, is_april, is_may, is_june,\n",
    "            is_july, is_august, is_september, is_october, is_november, \n",
    "            is_december, is_first_quarter_year, is_second_quarter_year, \n",
    "            is_third_quarter_year, is_forth_quarter_year, is_first_trimester_year, \n",
    "            is_second_trimester_year, is_third_trimester_year, is_first_half_year, \n",
    "            is_second_half_year]\n",
    "end\n",
    "\n",
    "function extract_time_features(string_time_hhmmss)\n",
    "    hour = parse(Int, string_time_hhmmss[1:2])\n",
    "    is_morning = 6 <= hour < 12? 1 : 0\n",
    "    is_afternoon = 13 <= hour < 18? 1 : 0\n",
    "    is_evenning = 18 <= hour < 20? 1 : 0\n",
    "    is_night = 20 <= hour <= 22? 1 : 0\n",
    "    is_late_night = 22 < hour <= 24 || 0 <= hour < 6? 1: 0\n",
    "    is_midday = 12 <= hour < 13? 1 : 0\n",
    "    is_launch_time = 11 <= hour <= 14? 1 : 0\n",
    "    is_end_work_day = 17 <= hour <= 19? 1 : 0\n",
    "    \n",
    "    return [is_morning, is_afternoon, is_evenning, is_night, is_late_night, \n",
    "            is_midday, is_launch_time, is_end_work_day]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "render_section(\"07\", \"02\", \"Features: Extract Age Features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "render_doc(\"extract_age_features(age)\",\n",
    "           \"Extract age feature vector\",\n",
    "          [(\"age\", \"Int\", \"Age in years\")],\n",
    "          [(\"_\", \"Array{Int,1}\", \"Feature vector of age\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "age_feature_names = [:is_age_under_25, :is_age_between_25_34, :is_age_between_35_44, \n",
    "                     :is_age_between_45_54, :is_age_between_55_64, :is_age_above_64,\n",
    "                     :is_young_adult, :is_old_adult]\n",
    "\n",
    "function extract_age_features(age)\n",
    "    \n",
    "    is_age_under_25      = age < 25? 1 : 0\n",
    "    is_age_between_25_34 = 25 <= age < 35? 1 : 0\n",
    "    is_age_between_35_44 = 35 <= age < 45? 1 : 0\n",
    "    is_age_between_45_54 = 45 <= age < 55? 1 : 0\n",
    "    is_age_between_55_64 = 55 <= age < 65? 1 : 0\n",
    "    is_age_above_64      = age >= 65? 1 : 0\n",
    "    \n",
    "    is_young_adult       = 25 <= age < 45? 1 : 0\n",
    "    is_old_adult         = 45 <= age < 65? 1 : 0\n",
    "    \n",
    "    return [is_age_under_25, is_age_between_25_34, is_age_between_35_44, \n",
    "            is_age_between_45_54, is_age_between_55_64, is_age_above_64,\n",
    "            is_young_adult, is_old_adult]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "render_section(\"08\", \"\", \"Functions: Export/Import Files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "render_doc(\"export_csv (df, file_path)\",\n",
    "           \"Export dataframe to CSV format\",\n",
    "           [(\"df\", \"DataFrame\", \"Dataframe to be exported\"),\n",
    "            (\"file_path\", \"AbstractString\", \"File path to save CSV file\")], [])\n",
    "\n",
    "render_doc(\"export_tsv (df, file_path)\",\n",
    "           \"Export dataframe to TSV format\",\n",
    "           [(\"df\", \"DataFrame\", \"Dataframe to be exported\"),\n",
    "            (\"file_path\", \"AbstractString\", \"File path to save TSV file\")], [])\n",
    "\n",
    "render_doc(\"export_gz (data, file_path)\",\n",
    "           \"Export string data in Gzip format\",\n",
    "           [(\"data\", \"AbstractString\", \"Data in string format to be compressed and exported\"),\n",
    "            (\"file_path\", \"AbstractString\", \"File path to store data in gzip format\")], [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "export_csv(df, file_path) = writetable(file_path, df)\n",
    "export_tsv(df, file_path) = writetable(file_path, df, separator=\"tsv\")\n",
    "function export_gz(data::AbstractString, file_path)\n",
    "    file = GZip.open(\"$file_path.gz\", \"w\")\n",
    "    write(file, data)\n",
    "    close(file)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "render_section(\"09\", \"\", \"Functions: Split Training and Validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "render_doc(\"split_train_val (df; train_size=.85, random_state=1)\",\n",
    "           \"Separate in train and validation dataframes\",\n",
    "           [(\"df\", \"DataFrame\", \"Original dataframe that will be splitted\"),\n",
    "            (\"train_size\", \"Float\", \"\"\"Size in porcentage of the training dataframe.\n",
    "              Default value = 0.85\"\"\"),\n",
    "            (\"random_state\", \"Int\", \"Random seed used. Default value = 1\")],\n",
    "           [(\"train\", \"DataFrame\", \"Train dataframe with train_size percentage\"),\n",
    "            (\"validation\", \"DataFrame\", \"Validation dataframe with 1-train_size percentage\")])\n",
    "\n",
    "render_doc(\"gen_train_val (train, features, label, train_size=.85, random_state=1)\",\n",
    "           \"Generate train and validation for x and y\",\n",
    "           [(\"train\", \"DataFrame\", \"Train dataframe that will be splitted\"),\n",
    "            (\"features\", \"Array{Symbol,1}\", \"Columns to consider as X (features)\"),\n",
    "            (\"label\", \"Symbol\", \"Column to consider as Y (output)\"),\n",
    "            (\"train_size\", \"Float\", \"\"\"Size in porcentage of the training dataframe.\n",
    "              Default value = 0.85\"\"\"),\n",
    "            (\"random_state\", \"Int\", \"Random seed used. Default value = 1\")],\n",
    "           [(\"train_x\", \"Array{Float,2}\", \"Train matrix with features\"),\n",
    "            (\"train_y\", \"Array{Float,1}\", \"Train array with outputs\"),\n",
    "            (\"val_x\", \"Array{Float,2}\", \"Validation dataframe with features\"),\n",
    "            (\"val_y\", \"Array{Float,1}\", \"Validation array with outputs\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function split_train_val(df; train_size=.85, random_state=1)\n",
    "    srand(random_state)\n",
    "    \n",
    "    nrows, ntraining_rows = size(df, 1), round(Int, size(df, 1) * train_size)\n",
    "    indexes               = shuffle(collect(1:nrows))\n",
    "    train                 = df[indexes[1:ntraining_rows], :]\n",
    "    validation            = df[indexes[ntraining_rows+1:end], :]\n",
    "    \n",
    "    return train, validation\n",
    "end\n",
    "\n",
    "function gen_train_val(train, features, label, train_size=.85, random_state=1)\n",
    "    X_train, X_val = split_train_val(train; train_size=.85, random_state=1)\n",
    "    train_x = Array{Float64,2}(X_train[:, features])\n",
    "    train_y = Array{Float64,1}(X_train[label])\n",
    "    val_x   = Array{Float64,2}(X_val[:, features])\n",
    "    val_y   = Array{Float64,1}(X_val[label])\n",
    "    return train_x, train_y, val_x, val_y\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "render_section(\"10\", \"\", \"Functions: XGB Auxiliary Tools\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "render_doc(\"gen_dtrain(train, features, label, train_size=.85, random_state=1)\",\n",
    "           \"Generate DMatrices for train and validation to use on XGBoost\",\n",
    "           [(\"train\", \"DataFrame\", \"Train dataframe that will be splitted\"),\n",
    "            (\"features\", \"Array{Symbol,1}\", \"Columns to consider as X (features)\"),\n",
    "            (\"label\", \"Symbol\", \"Column to consider as Y (output)\"),\n",
    "            (\"train_size\", \"Float\", \"\"\"Size in porcentage of the training dataframe.\n",
    "              Default value = 0.85\"\"\"),\n",
    "            (\"random_state\", \"Int\", \"Random seed used. Default value = 1\")],\n",
    "           [(\"dtrain\", \"DMatrix\", \"Train matrix to XGB\"),\n",
    "            (\"dval\", \"DMatrix\", \"Validation matrix to XGB\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function gen_dtrain(train, features, label, train_size=.85, random_state=1)\n",
    "    train_x, train_y, val_x, val_y = gen_train_val(train, features, label, \n",
    "                                                   train_size, random_state)\n",
    "    dtrain  = DMatrix(train_x, label=train_y)\n",
    "    dval    = DMatrix(val_x, label=val_y)\n",
    "    return dtrain, dval\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "render_section(\"11\", \"\", \"Functions: GLM Auxiliary Tools\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "render_doc(\"gen_formula (features, label)\",\n",
    "           \"Generate formula y ~ X\",\n",
    "           [(\"features\", \"Array{Symbol,1}\", \"Feature that will be used as X\"),\n",
    "            (\"label\", \"Symbol\", \"Output label as y\")],\n",
    "           [(\"formula\", \"Formula\", \"Formula to be used in GLM package\")])\n",
    "\n",
    "render_doc(\"gen_formulas (features, label)\",\n",
    "           \"Generate all valids formules between features x label\",\n",
    "          [(\"features\", \"Array{Symbol,1}\", \"Features that will be used in combination\"),\n",
    "           (\"label\", \"Symbol\", \"Output label (i.e., Y)\"),\n",
    "           (\"min_vars_formula\", \"Int\", \"Minimum number of variables in formula (Default=1)\"),\n",
    "           (\"max_vars_formula\", \"Int\", \"Maximum number of variables in formula (Default=Max Features)\")],\n",
    "          [(\"formulas\", \"Array{Formula,1}\", \"Array of formulas to be used in GLM package\")])\n",
    "\n",
    "render_doc(\"gen_formulas (features, feature_space, label, min_vars_formula, max_vars_formula)\",\n",
    "           \"Generate all valids formules between feature space X and label\",\n",
    "          [(\"features\", \"Array{Symbol,1}\", \"Features that will be used in combination\"),\n",
    "           (\"feature_space\", \"OrderedDict\", \"Feature space with its start and end index\"),\n",
    "           (\"label\", \"Symbol\", \"Output label (i.e., Y)\"),\n",
    "           (\"min_vars_formula\", \"Int\", \"Minimum number of variables in formula (Default=1)\"),\n",
    "           (\"max_vars_formula\", \"Int\", \"Maximum number of variables in formula (Default=Max Features)\")],\n",
    "          [(\"formulas\", \"Array{Formula,1}\", \"Array of formulas to be used in GLM package\")])\n",
    "\n",
    "render_doc(\"gen_glm (train, formulas, family=Binomial(), link=LogitLink())\",\n",
    "           \"\"\"Generate Generalized Linear Models (GLMs). Check the \n",
    "              <a src=\"https://github.com/JuliaStats/GLM.jl\">original package</a>\n",
    "              for more information\"\"\",\n",
    "          [(\"train\", \"DataFrame\", \"Train data\"),\n",
    "           (\"formulas\", \"Array{Formula,1}\", \"Array with the formulas\"),\n",
    "           (\"family\", \"Distribution\", \"Family discribution (e.g., Binomial, Gamma, etc)\"),\n",
    "           (\"link\", \"\", \"Link from distribution. Default is LogitLink for logistic regression\")],\n",
    "          [(\"models\", \"Dict\", \"A dict with key as formula and value as GLM model\")])\n",
    "\n",
    "render_doc(\"train_glmnet (X, y, family=Normal(), alpha=1)\",\n",
    "           \"\"\"Train GLMNet models.</br></br>For more information go to\n",
    "              <a href=\"https://github.com/simonster/GLMNet.jl\">GLMNet package site</a>\"\"\",\n",
    "           [(\"X\", \"Array{Number,2}\", \"Matrix with the data for training\"),\n",
    "            (\"y\", \"Array{Number,1}\", \"Output values\"),\n",
    "            (\"family\", \"Distributions\", \"\"\"Family distribution. Only accepts\n",
    "              Normal() and Poisson() (regression) and Binomial() (Logistic)\"\"\"),\n",
    "            (\"alpha\", \"Float64\", \"\"\"The tradeoff between lasso and ridge regression.\n",
    "              This defaults to 1.0, which specifies a lasso model\"\"\")],\n",
    "           [(\"models\", \"GLMNetPath\", \"Family of GLMNet models\")])\n",
    "\n",
    "render_doc(\"predict (model::GLMNet.GLMNetPath, X)\",\n",
    "           \"Predict with a family of GLMNets from a given input X\",\n",
    "           [(\"model\", \"GLMNetPath\", \"Family model of GLMNets\"),\n",
    "            (\"X\", \"Array{Number,2}\", \"Input data to be predicted\")],\n",
    "           [(\"_\", \"Array{Float64,2}\", \"\"\"A matrix nxm with all predictions for the\n",
    "                                        <b>n</b> instances per each <b>m</b> GLMNet model\"\"\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gen_formula(features, label) = eval(parse(string(label, \"~\", join(features, \"+\"))))\n",
    "\n",
    "function gen_formulas(features::Array{Symbol,1},\n",
    "                      label::Symbol,\n",
    "                      min_vars_formula::Int64=1,\n",
    "                      max_vars_formula::Int64=length(features))\n",
    "    feature_space = gen_feature_space(features)\n",
    "    formulas = gen_formulas(features, feature_space, label, \n",
    "                            min_vars_formula, max_vars_formula) \n",
    "    return formulas\n",
    "end\n",
    "\n",
    "function gen_formulas(features::Array{Symbol,1}, \n",
    "                      feature_space::OrderedDict{Symbol,Tuple{Int64,Int64}},\n",
    "                      label::Symbol,\n",
    "                      min_vars_formula::Int64=1,\n",
    "                      max_vars_formula::Int64=length(feature_space))\n",
    "    key_features = collect(keys(feature_space))\n",
    "    key_features_combinations = get_combinations(key_features, min_vars_formula, max_vars_formula)\n",
    "\n",
    "    formulas = Formula[]\n",
    "    for feature_combination in key_features_combinations\n",
    "        expanded_features = expand_feature_space(feature_combination, feature_space, features)\n",
    "        formula = eval(parse(string(label, \"~\", join(expanded_features, \"+\"))))\n",
    "        push!(formulas, formula)\n",
    "    end\n",
    "    return formulas\n",
    "end\n",
    "\n",
    "function get_combinations(elements, min, max)\n",
    "    combinations = []\n",
    "    for k=min:max\n",
    "        append!(combinations, collect(subsets(elements, k)))\n",
    "    end\n",
    "    return combinations\n",
    "end\n",
    "\n",
    "function gen_glm(train, formulas, family=Binomial(), link=LogitLink())\n",
    "    models = Dict()\n",
    "    for formula in formulas\n",
    "        try\n",
    "            model = glm(formula, train, family, link)\n",
    "            models[formula] = model\n",
    "        catch\n",
    "        end\n",
    "    end\n",
    "    return models\n",
    "end\n",
    "\n",
    "function train_glmnet(X, y, family=Normal(), alpha=1)\n",
    "    if isa(family, Binomial)\n",
    "        y_adjusted = vcat([v > 0? [0, 1] : [1, 0] for v in y]...)\n",
    "        y_adjusted = reshape(y_adjusted, 2, length(y))'\n",
    "    else\n",
    "        y_adjusted = copy(y)\n",
    "    end\n",
    "    model = glmnet(X, y_adjusted, family, alpha=alpha)\n",
    "    return model\n",
    "end\n",
    "predict(model::GLMNet.GLMNetPath, X) = GLMNet.predict(model, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test GLMNet Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "srand(1)\n",
    "X = Array{Float64, 2}(df[:, features])\n",
    "y = Array{Float64, 1}(df[:, label])\n",
    "yl = Array{Float64, 1}(rand([0.0, 1.0], 5))\n",
    "m = train_glmnet(X, yl, Binomial())\n",
    "results = predict(m, X)\n",
    "@test isa(m, GLMNet.GLMNetPath)\n",
    "@test size(results,1) == 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Expanded Feature Vector + Formulas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = [y ~ FeatureA_1 + FeatureA_2 + FeatureA_3, \n",
    "          y ~ FeatureB,\n",
    "          y ~ FeatureC_1 + FeatureC_2,\n",
    "          y ~ FeatureA_1 + FeatureA_2 + FeatureA_3 + FeatureB,\n",
    "          y ~ FeatureA_1 + FeatureA_2 + FeatureA_3 + FeatureC_1 + FeatureC_2,\n",
    "          y ~ FeatureB + FeatureC_1 + FeatureC_2,\n",
    "          y ~ FeatureA_1 + FeatureA_2 + FeatureA_3 + FeatureB + FeatureC_1 + FeatureC_2]\n",
    "@test string(gen_formulas(features, feature_space, :y)) == string(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "render_section(\"12\", \"\", \"Functions: Decision Trees, Random Forests and Tree related\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "render_doc(\"train_decision_tree (train_x, train_y; leaves_purity=.9)\",\n",
    "           \"\"\"Train a decision tree. <br/><br/> Source package:\n",
    "              <a href=\"https://github.com/bensadeghi/DecisionTree.jl\">\n",
    "              https://github.com/bensadeghi/DecisionTree.jl</a>\"\"\",\n",
    "           [(\"train_x\", \"Array{Float64,2}\", \"Matrix with features data\"),\n",
    "            (\"train_y\", \"Array{Float64,1}\", \"Array with output data\"),\n",
    "            (\"leaves_purity\", \"Float64\", \"Leaves purity percentage (Default=.9). To prune tree\")],\n",
    "           [(\"model\", \"Decision Tree Model\", \"A decision tree model fitted with the training data\")])\n",
    "\n",
    "render_doc(\"train_random_forest (train_x, train_y; random_features=2, num_trees=10, portion_samples=.5)\",\n",
    "           \"\"\"Train a random forest. <br/><br/> Source package:\n",
    "              <a href=\"https://github.com/bensadeghi/DecisionTree.jl\">\n",
    "              https://github.com/bensadeghi/DecisionTree.jl</a>\"\"\",\n",
    "           [(\"train_x\", \"Array{Float64,2}\", \"Matrix with features data\"),\n",
    "            (\"train_y\", \"Array{Float64,1}\", \"Array with output data\"),\n",
    "            (\"random_features\", \"Int64\", \"Random feature selection (Default=2)\"),\n",
    "            (\"num_trees\", \"Int64\", \"Number of trees used in model (Default=10)\"),\n",
    "            (\"portion_samples\", \"Float64\", \"Number of samples per tree (Default=.5)\")],\n",
    "           [(\"model\", \"Random Forest Model\", \"A random forest model fitted with the training data\")])\n",
    "\n",
    "render_doc(\"train_adaptive_boosted_trees (train_x, train_y; num_iteration=7)\",\n",
    "           \"\"\"Train Adaptive Boosted Trees. <br/><br/> Source package:\n",
    "              <a href=\"https://github.com/bensadeghi/DecisionTree.jl\">\n",
    "              https://github.com/bensadeghi/DecisionTree.jl</a>\"\"\",\n",
    "           [(\"train_x\", \"Array{Float64,2}\", \"Matrix with features data\"),\n",
    "            (\"train_y\", \"Array{Float64,1}\", \"Array with output data\"),\n",
    "            (\"num_iteration\", \"Int64\", \"Number of algorithm iteration (Default=7)\")],\n",
    "           [(\"model\", \"Adaptive boosted trees Model\", \"\"\"Adaptive boosted trees model\n",
    "                                                         fitted with the training data\"\"\"),\n",
    "            (\"coefficients\", \"\", \"Trees coefficients\")])\n",
    "\n",
    "render_doc(\"predict (model, x)\",\n",
    "           \"Predict output from a Decision Tree model and a given input x\",\n",
    "         [(\"model\", \"DecisionTree.Node\", \"Decision tree model\"),\n",
    "          (\"x\", \"Array{Float64,2}\", \"Matrix with data to be predicted\")],\n",
    "         [(\"_\", \"Array\", \"Predicted output for classification or regression\")])\n",
    "\n",
    "render_doc(\"predict (model, x)\",\n",
    "           \"Predict output from a Random Forest model and a given input x\",\n",
    "         [(\"model\", \"DecisionTree.Ensemble\", \"Decision tree model\"),\n",
    "          (\"x\", \"Array{Float64,2}\", \"Matrix with data to be predicted\")],\n",
    "         [(\"_\", \"Array\", \"Predicted output for classification or regression\")])\n",
    "\n",
    "render_doc(\"predict (model, coeffs, x)\",\n",
    "           \"Predict output from Adaptive boosted trees model and a given input x\",\n",
    "         [(\"model\", \"DecisionTree.Ensemble\", \"Adaptive boosted tree model\"),\n",
    "          (\"coeffs\", \"Array{Float64,1}\", \"Coefficients from the adaptive boosted trees\"),\n",
    "          (\"x\", \"Array{Float64,2}\", \"Matrix with data to be predicted\")],\n",
    "         [(\"_\", \"Array\", \"Predicted output for classification or regression\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function train_decision_tree(train_x, train_y; leaves_purity=.9)\n",
    "    model = build_tree(train_y, train_x)\n",
    "    model = prune_tree(model, leaves_purity)\n",
    "    return model\n",
    "end\n",
    "\n",
    "function train_random_forest(train_x, train_y; random_features=2,\n",
    "                             num_trees=10, portion_samples=.5)\n",
    "    model = build_forest(train_y, train_x, random_features,\n",
    "                         num_trees, portion_samples)\n",
    "    return model\n",
    "end\n",
    "\n",
    "function train_adaptive_boosted_trees(train_x, train_y; num_iteration=7)\n",
    "    model, coefficients = build_adaboost_stumps(train_y, train_x, num_iteration)\n",
    "    return model, coefficients\n",
    "end\n",
    "\n",
    "predict(model::DecisionTree.Node, x) = Array{Float64}(apply_tree(model, x))\n",
    "predict(model::DecisionTree.Ensemble, x) = Array{Float64}(apply_forest(model, x))\n",
    "predict(model::DecisionTree.Ensemble, coeffs::Array{Float64}, x) = Array{Float64}(apply_adaboost_stumps(model, coeffs, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "render_section(\"1X\", \"\", \"FastFM for Factorization Machines\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"method\">\n",
       "    <div class=\"method_title\"><span class=\"tt\">Method: </span><b>train_fmregression (X, y; n_iter=1000, init_stdev=.1, rank=2, l2_reg_w=.1, l2_reg_V=.5)</b></div>\n",
       "        <div class=\"method_body\">\n",
       "            <div class=\"method_cell\">\n",
       "                <div class=\"method_cell_title\"><span class=\"tt\"><b>Description</b></span></div>\n",
       "                <div class=\"method_cell_body\">\n",
       "                    <span class=\"tt\">Regression train with Alternating Least Squares (ALS) from FastFM Library.<br/><br/>\n",
       "See more information about this method in \n",
       "<a href=\"http://ibayer.github.io/fastFM/tutorial.html\">FastML tutorial</a>.</span>\n",
       "                </div>\n",
       "            </div>\n",
       "            <div class=\"method_cell\">\n",
       "                <div class=\"method_cell_title\"><span class=\"tt\"><b>Arguments</b></span></div>\n",
       "                <div class=\"method_cell_body\">\n",
       "                    <ul>\n",
       "                        <li><span class=\"tt\">X, <b>Array{Float64,2}</b>: Matrix with features data.</span></li>\n",
       "<li><span class=\"tt\">y, <b>Array{Float64,1}</b>: Array with output data.</span></li>\n",
       "<li><span class=\"tt\">n_iter, <b>Int</b>: Iteration number (Default=1000).</span></li>\n",
       "<li><span class=\"tt\">init_stdev, <b>Float64</b>:  (Default=.1).</span></li>\n",
       "<li><span class=\"tt\">rank, <b>Int</b>:  (Default=2).</span></li>\n",
       "<li><span class=\"tt\">l2_reg_w, <b>Float64</b>:  (Default=.1).</span></li>\n",
       "<li><span class=\"tt\">l2_reg_V, <b>Float64</b>:  (Default=.5).</span></li>\n",
       "\n",
       "                    </ul>\n",
       "                </div>\n",
       "            </div>\n",
       "            <div class=\"method_cell\">\n",
       "                <div class=\"method_cell_title\"><span class=\"tt\"><b>Outputs</b></span></div>\n",
       "                <div class=\"method_cell_body\">\n",
       "                    <ul>\n",
       "                        <li><span class=\"tt\">model, <b></b>: Model fitted with data X and y.</span></li>\n",
       "\n",
       "                    </ul>\n",
       "                </div>\n",
       "            </div>\n",
       "        </div>\n",
       "    </div>\n",
       "<div/>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"method\">\n",
       "    <div class=\"method_title\"><span class=\"tt\">Method: </span><b>train_fmclassification_sgd (X, y; n_iter=1000, init_stdev=.1, rank=2, l2_reg_w=0, l2_reg_V=0, step_size=.1)</b></div>\n",
       "        <div class=\"method_body\">\n",
       "            <div class=\"method_cell\">\n",
       "                <div class=\"method_cell_title\"><span class=\"tt\"><b>Description</b></span></div>\n",
       "                <div class=\"method_cell_body\">\n",
       "                    <span class=\"tt\">Classification train with Stochastic Gradient Descent (SGD) from FastFM Library.<br/><br/>\n",
       "See more information about this method in \n",
       "<a href=\"http://ibayer.github.io/fastFM/tutorial.html\">FastML tutorial</a>.</span>\n",
       "                </div>\n",
       "            </div>\n",
       "            <div class=\"method_cell\">\n",
       "                <div class=\"method_cell_title\"><span class=\"tt\"><b>Arguments</b></span></div>\n",
       "                <div class=\"method_cell_body\">\n",
       "                    <ul>\n",
       "                        <li><span class=\"tt\">X, <b>Array{Float64,2}</b>: Matrix with features data.</span></li>\n",
       "<li><span class=\"tt\">y, <b>Array{Float64,1}</b>: Array with output data.</span></li>\n",
       "<li><span class=\"tt\">n_iter, <b>Int</b>: Iteration number (Default=1000).</span></li>\n",
       "<li><span class=\"tt\">init_stdev, <b>Float64</b>:  (Default=.1).</span></li>\n",
       "<li><span class=\"tt\">rank, <b>Int</b>:  (Default=2).</span></li>\n",
       "<li><span class=\"tt\">l2_reg_w, <b>Float64</b>:  (Default=.1).</span></li>\n",
       "<li><span class=\"tt\">l2_reg_V, <b>Float64</b>:  (Default=.5).</span></li>\n",
       "<li><span class=\"tt\">step_size, <b>Float64</b>:  (Default=.1).</span></li>\n",
       "\n",
       "                    </ul>\n",
       "                </div>\n",
       "            </div>\n",
       "            <div class=\"method_cell\">\n",
       "                <div class=\"method_cell_title\"><span class=\"tt\"><b>Outputs</b></span></div>\n",
       "                <div class=\"method_cell_body\">\n",
       "                    <ul>\n",
       "                        <li><span class=\"tt\">model, <b></b>: Model fitted with data X and y.</span></li>\n",
       "\n",
       "                    </ul>\n",
       "                </div>\n",
       "            </div>\n",
       "        </div>\n",
       "    </div>\n",
       "<div/>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"method\">\n",
       "    <div class=\"method_title\"><span class=\"tt\">Method: </span><b>train_predict_fmclassification_mcmc (X, y, Xpred; n_iter=1000, rank=2, init_stdev=.1)</b></div>\n",
       "        <div class=\"method_body\">\n",
       "            <div class=\"method_cell\">\n",
       "                <div class=\"method_cell_title\"><span class=\"tt\"><b>Description</b></span></div>\n",
       "                <div class=\"method_cell_body\">\n",
       "                    <span class=\"tt\">Classification train and prediction with Markov Chain Monte Carlo (MCMC) from FastFM Library.<br/>\n",
       "y need be -1 or 1.<br/>\n",
       "See more information about this method in \n",
       "<a href=\"http://ibayer.github.io/fastFM/tutorial.html\">FastML tutorial</a>.</span>\n",
       "                </div>\n",
       "            </div>\n",
       "            <div class=\"method_cell\">\n",
       "                <div class=\"method_cell_title\"><span class=\"tt\"><b>Arguments</b></span></div>\n",
       "                <div class=\"method_cell_body\">\n",
       "                    <ul>\n",
       "                        <li><span class=\"tt\">X, <b>Array{Float64,2}</b>: Matrix with features data.</span></li>\n",
       "<li><span class=\"tt\">y, <b>Array{Float64,1}</b>: Array with output data.</span></li>\n",
       "<li><span class=\"tt\">Xpred, <b>Array{Float64,1}</b>: Array with output data.</span></li>\n",
       "<li><span class=\"tt\">n_iter, <b>Int</b>: Iteration number (Default=1000).</span></li>\n",
       "<li><span class=\"tt\">init_stdev, <b>Float64</b>:  (Default=.1).</span></li>\n",
       "<li><span class=\"tt\">rank, <b>Int</b>:  (Default=2).</span></li>\n",
       "\n",
       "                    </ul>\n",
       "                </div>\n",
       "            </div>\n",
       "            <div class=\"method_cell\">\n",
       "                <div class=\"method_cell_title\"><span class=\"tt\"><b>Outputs</b></span></div>\n",
       "                <div class=\"method_cell_body\">\n",
       "                    <ul>\n",
       "                        <li><span class=\"tt\">yhat, <b>Array{Float64, 1}</b>: Predicted values.</span></li>\n",
       "\n",
       "                    </ul>\n",
       "                </div>\n",
       "            </div>\n",
       "        </div>\n",
       "    </div>\n",
       "<div/>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "render_doc(\"train_fmregression (X, y; n_iter=1000, init_stdev=.1, rank=2, l2_reg_w=.1, l2_reg_V=.5)\",\n",
    "           \"\"\"Regression train with Alternating Least Squares (ALS) from FastFM Library.<br/><br/>\n",
    "              See more information about this method in \n",
    "              <a href=\"http://ibayer.github.io/fastFM/tutorial.html\">FastML tutorial</a>\"\"\",\n",
    "         [(\"X\", \"Array{Float64,2}\", \"Matrix with features data\"),\n",
    "          (\"y\", \"Array{Float64,1}\", \"Array with output data\"),\n",
    "          (\"n_iter\", \"Int\", \"Iteration number (Default=1000)\"),\n",
    "          (\"init_stdev\", \"Float64\", \" (Default=.1)\"),\n",
    "          (\"rank\", \"Int\", \" (Default=2)\"),\n",
    "          (\"l2_reg_w\", \"Float64\", \" (Default=.1)\"),\n",
    "          (\"l2_reg_V\", \"Float64\", \" (Default=.5)\")],\n",
    "         [(\"model\", \"\", \"Model fitted with data X and y\")])\n",
    "\n",
    "render_doc(\"train_fmclassification_sgd (X, y; n_iter=1000, init_stdev=.1, rank=2, l2_reg_w=0, l2_reg_V=0, step_size=.1)\",\n",
    "           \"\"\"Classification train with Stochastic Gradient Descent (SGD) from FastFM Library.<br/><br/>\n",
    "              See more information about this method in \n",
    "              <a href=\"http://ibayer.github.io/fastFM/tutorial.html\">FastML tutorial</a>\"\"\",\n",
    "         [(\"X\", \"Array{Float64,2}\", \"Matrix with features data\"),\n",
    "          (\"y\", \"Array{Float64,1}\", \"Array with output data\"),\n",
    "          (\"n_iter\", \"Int\", \"Iteration number (Default=1000)\"),\n",
    "          (\"init_stdev\", \"Float64\", \" (Default=.1)\"),\n",
    "          (\"rank\", \"Int\", \" (Default=2)\"),\n",
    "          (\"l2_reg_w\", \"Float64\", \" (Default=.1)\"),\n",
    "          (\"l2_reg_V\", \"Float64\", \" (Default=.5)\"),\n",
    "          (\"step_size\", \"Float64\", \" (Default=.1)\")],\n",
    "         [(\"model\", \"\", \"Model fitted with data X and y\")])\n",
    "\n",
    "render_doc(\"train_predict_fmclassification_mcmc (X, y, Xpred; n_iter=1000, rank=2, init_stdev=.1)\",\n",
    "           \"\"\"Classification train and prediction with Markov Chain Monte Carlo (MCMC) from FastFM Library.<br/>\n",
    "              y need be -1 or 1.<br/>\n",
    "              See more information about this method in \n",
    "              <a href=\"http://ibayer.github.io/fastFM/tutorial.html\">FastML tutorial</a>\"\"\",\n",
    "         [(\"X\", \"Array{Float64,2}\", \"Matrix with features data\"),\n",
    "          (\"y\", \"Array{Float64,1}\", \"Array with output data\"),\n",
    "          (\"Xpred\", \"Array{Float64,1}\", \"Array with output data\"),    \n",
    "          (\"n_iter\", \"Int\", \"Iteration number (Default=1000)\"),\n",
    "          (\"init_stdev\", \"Float64\", \" (Default=.1)\"),\n",
    "          (\"rank\", \"Int\", \" (Default=2)\")],\n",
    "         [(\"yhat\", \"Array{Float64, 1}\", \"Predicted values\")])\n",
    "\n",
    "render_doc(\"predict (::Type{FastFMModel}, model, X)\",\n",
    "           \"\"\"Make prediction on FastFMModel.\"\"\",\n",
    "         [(\"X\", \"Array{Float64,2}\", \"Matrix with features data\"),\n",
    "          (\"y\", \"Array{Float64,1}\", \"Array with output data\"),\n",
    "          (\"Xpred\", \"Array{Float64,1}\", \"Array with output data\"),    \n",
    "          (\"n_iter\", \"Int\", \"Iteration number (Default=1000)\"),\n",
    "          (\"init_stdev\", \"Float64\", \" (Default=.1)\"),\n",
    "          (\"rank\", \"Int\", \" (Default=2)\")],\n",
    "         [(\"yhat\", \"Array{Float64, 1}\", \"Predicted values\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predict (generic function with 1 method)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type FastFMModel end\n",
    "\n",
    "function train_fmregression(X, y; n_iter=1000, init_stdev=.1, rank=2, l2_reg_w=.1, l2_reg_V=.5)\n",
    "    sparse_X = scipy_sparse.csr_matrix(X)\n",
    "    model = ffm_als.FMRegression(n_iter=n_iter, init_stdev=init_stdev, rank=rank,\n",
    "                                 l2_reg_w=l2_reg_w, l2_reg_V=l2_reg_V)\n",
    "    model[:fit](sparse_X, y)\n",
    "    return model\n",
    "end\n",
    "\n",
    "function train_fmclassification_sgd(X, y; n_iter=1000, init_stdev=.1, rank=2, l2_reg_w=0, l2_reg_V=0, step_size=.1)\n",
    "    sparse_X = scipy_sparse.csr_matrix(X)\n",
    "    model = ffm_sgd.FMClassification(n_iter=n_iter, init_stdev=init_stdev, l2_reg_w=l2_reg_w,\n",
    "                                     l2_reg_V=l2_reg_V, rank=rank, step_size=step_size)\n",
    "    model[:fit](sparse_X, y)\n",
    "    return model\n",
    "end\n",
    "\n",
    "function train_predict_fmclassification_mcmc(X, y, Xpred; n_iter=1000, rank=2, init_stdev=.1)\n",
    "    sparse_X = scipy_sparse.csr_matrix(X)\n",
    "    sparse_Xpred = scipy_sparse.csr_matrix(X)\n",
    "    model = ffm_mcmc.FMClassification(n_iter=n_iter, rank=rank, init_stdev=init_stdev)\n",
    "    yhat = model[:fit_predict](sparse_X, y, sparse_Xpred)\n",
    "    return yhat\n",
    "end\n",
    "\n",
    "predict(::Type{FastFMModel}, model, X) = model[:predict](scipy_sparse.csr_matrix(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test FastFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Scenario 01: Regression with ALS\n",
    "model = train_fmregression(X, y)\n",
    "@test typeof(predict(FastFMModel, model, X)) == Array{Float64,1}\n",
    "\n",
    "# Scenario 02: Classification with SGD\n",
    "model = train_fmclassification_sgd(X, y)\n",
    "@test typeof(predict(FastFMModel, model, X)) == Array{Float64,1}\n",
    "\n",
    "# Scenario 03: Classification with MCMC\n",
    "@test(typeof(train_predict_fmclassification_mcmc(X, y, X)) == Array{Float64, 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "render_section(\"1X\", \"\", \"Functions : K Nearest Neighbors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ToDo: Implement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "render_section(\"1X\", \"\", \"Regularized Empirical Risk Minimization Models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "render_doc(\"train_svm_rerm (X, y; optimizer=:l_bfgs, λ=1.0)\",\n",
    "           \"\"\"Train SVM for Regularized Empirical Risk Minimization</br></br>\n",
    "              For more information check <a hraf=\"https://github.com/JuliaStats/RegERMs.jl\">\n",
    "              package page</a>\"\"\",\n",
    "           [(\"X\", \"Array{Number,2}\", \"Input matrix for training\"),\n",
    "            (\"y\", \"Array{Number,1}\", \"Output array for training\"),\n",
    "            (\"optimizer\", \"Symbol\", \"Optimized used in training. Can be :l_bfgs or :sgv (Default=:l_bfgs)\"),\n",
    "            (\"λ\", \"Float64\", \"Regularization parameter\")],\n",
    "           [((\"model\", \"RegressionModel\", \"Model fitted with the (X, y) data\"))])\n",
    "\n",
    "render_doc(\"train_ridge_regression_rerm (X, y; optimizer=:l_bfgs, λ=1.0)\",\n",
    "           \"\"\"Train Ridge Regression for Regularized Empirical Risk Minimization</br></br>\n",
    "              For more information check <a hraf=\"https://github.com/JuliaStats/RegERMs.jl\">\n",
    "              package page</a>\"\"\",\n",
    "           [(\"X\", \"Array{Number,2}\", \"Input matrix for training\"),\n",
    "            (\"y\", \"Array{Number,1}\", \"Output array for training\"),\n",
    "            (\"optimizer\", \"Symbol\", \"Optimized used in training. Can be :l_bfgs or :sgv (Default=:l_bfgs)\"),\n",
    "            (\"λ\", \"Float64\", \"Regularization parameter\")],\n",
    "           [((\"model\", \"RegressionModel\", \"Model fitted with the (X, y) data\"))])\n",
    "\n",
    "render_doc(\"train_logistic_regression_rerm (X, y; optimizer=:l_bfgs, λ=1.0)\",\n",
    "           \"\"\"Train Logistic Regression for Regularized Empirical Risk Minimization</br></br>\n",
    "              For more information check <a hraf=\"https://github.com/JuliaStats/RegERMs.jl\">\n",
    "              package page</a>\"\"\",\n",
    "           [(\"X\", \"Array{Number,2}\", \"Input matrix for training\"),\n",
    "            (\"y\", \"Array{Number,1}\", \"Output array for training\"),\n",
    "            (\"optimizer\", \"Symbol\", \"Optimized used in training. Can be :l_bfgs or :sgv (Default=:l_bfgs)\"),\n",
    "            (\"λ\", \"Float64\", \"Regularization parameter\")],\n",
    "           [((\"model\", \"RegressionModel\", \"Model fitted with the (X, y) data\"))])\n",
    "\n",
    "render_doc(\"train_multi_logistic_regression_rerm (X, y; optimizer=:l_bfgs, λ=1.0)\",\n",
    "           \"\"\"Train Multi-Class Logistic Regression for Regularized Empirical Risk Minimization</br></br>\n",
    "              For more information check <a hraf=\"https://github.com/JuliaStats/RegERMs.jl\">\n",
    "              package page</a>\"\"\",\n",
    "           [(\"X\", \"Array{Number,2}\", \"Input matrix for training\"),\n",
    "            (\"y\", \"Array{Number,1}\", \"Output array for training\"),\n",
    "            (\"optimizer\", \"Symbol\", \"Optimized used in training. Can be :l_bfgs or :sgv (Default=:l_bfgs)\"),\n",
    "            (\"λ\", \"Float64\", \"Regularization parameter\")],\n",
    "           [((\"model\", \"RegressionModel\", \"Model fitted with the (X, y) data\"))])\n",
    "\n",
    "render_doc(\"predict{T<:RegERMs.RegressionModel}(model::T, X)\", \n",
    "           \"\"\"Predict output based on regression model and X given\"\"\", \n",
    "           [(\"model\", \"RegressionModel\", \"Model fitted with the (X, y) data\"), \n",
    "            (\"X\", \"Array{Number,2}\", \"Input matrix\")],\n",
    "           [(\"_\", \"Array{Number, 1}\", \"Predict array values\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "abstract RegularizedEmpiricalRiskMinimizationModel\n",
    "abstract SVMRERM <: RegularizedEmpiricalRiskMinimizationModel\n",
    "abstract RidgeRERM <: RegularizedEmpiricalRiskMinimizationModel\n",
    "abstract LogisticRERM <: RegularizedEmpiricalRiskMinimizationModel\n",
    "abstract MLogisticRERM <: RegularizedEmpiricalRiskMinimizationModel\n",
    "\n",
    "train_svm_rerm(X, y; optimizer=:l_bfgs, λ=1.0) = train_rerm(X, y, SVMRERM, optimizer, λ)\n",
    "train_ridge_regression_rerm(X, y; optimizer=:l_bfgs, λ=1.0) = train_rerm(X, y, RidgeRERM, optimizer, λ)\n",
    "train_logistic_regression_rerm(X, y; optimizer=:l_bfgs, λ=1.0) = train_rerm(X, y, LogisticRERM, optimizer, λ)\n",
    "train_multi_logistic_regression_rerm(X, y; optimizer=:l_bfgs, λ=1.0) = train_rerm(X, y, MLogisticRERM, optimizer, λ)\n",
    "\n",
    "function train_rerm(X, y, rerm_model, optimizer, λ)\n",
    "    is(rerm_model, SVMRERM) && (model = RegERMs.SVM(X, y, kernel=:linear, λ=λ))\n",
    "    is(rerm_model, RidgeRERM) && (model = RegERMs.RidgeReg(X, y, λ=λ))\n",
    "    is(rerm_model, LogisticRERM) && (model = RegERMs.BinomialLogReg(X, y, λ=λ))\n",
    "    is(rerm_model, MLogisticRERM) && (model = RegERMs.MultinomialLogReg(X, y, λ=λ))\n",
    "    model = optimize(model, optimizer=optimizer)\n",
    "    return model\n",
    "end\n",
    "\n",
    "predict{T<:RegERMs.RegressionModel}(model::T, X) = RegERMs.predict(model, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Regularized Empirical Risk Minimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = train_svm_rerm(X, y)\n",
    "@test predict(model, X) == fill(-1.0, 5)\n",
    "\n",
    "# Bug in Ridge\n",
    "# model = train_ridge_regression_rerm(X, y)\n",
    "# predict(model, X)\n",
    "\n",
    "model = train_logistic_regression_rerm(X, [-1, -1, 1, 1, 1])\n",
    "@test predict(model, X) == fill(1.0, 5)\n",
    "\n",
    "model = train_multi_logistic_regression_rerm(X, [1, 1, 2, 2, 3])\n",
    "@test predict(model, X) == [2, 1, 1, 2, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "render_section(\"13\", \"\", \"Functions: Scikit Machine Learning Models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "render_section(\"13\", \"01\", \"Define Scikit Models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function create_bagging_model(base_model)\n",
    "    return ensemble.BaggingClassifier(\n",
    "        base_model, max_samples=0.5, max_features=0.5, \n",
    "        random_state=0, n_jobs=-1)\n",
    "end\n",
    "\n",
    "function create_adaboost_model(base_model)\n",
    "    return ensemble.AdaBoostClassifier(\n",
    "        base_model, n_estimators=10, random_state=0,\n",
    "        algorithm=\"SAMME\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scikit_regressor_models = Dict(\n",
    "    :OLS                => sklm.LinearRegression(),\n",
    "    :Ridge              => sklm.Ridge(alpha=.5), \n",
    "    :Lasso              => sklm.Lasso(alpha=.5), \n",
    "    :ElasticNet         => sklm.ElasticNet(alpha=.5, l1_ratio=0.5), \n",
    "    :LARS               => sklm.Lars(), \n",
    "    :LassoLARS          => sklm.LassoLars(alpha=1),\n",
    "    :BayesianRidge      => sklm.BayesianRidge(),\n",
    "    :Perceptron         => sklm.Perceptron(penalty=\"elasticnet\", alpha=.5)\n",
    ")\n",
    "\n",
    "scikit_classifier_models = Dict(\n",
    "    :LogisticRegression => sklm.LogisticRegression(),\n",
    "    :SGDClassifier      => sklm.SGDClassifier(alpha=.5),\n",
    "    :PassiveAggressiveClassifier => sklm.PassiveAggressiveClassifier(),\n",
    "    :SVMClassifier      => svm.SVC(), # Too slow!! May crash!\n",
    "    :kNN                => knn.KNeighborsClassifier(n_neighbors=2, algorithm=\"ball_tree\"),\n",
    "    :NaiveBayes         => naive_bayes.GaussianNB(),\n",
    "    :DecisionTree       => tree.DecisionTreeClassifier(),\n",
    "    :ExtremyTree        => tree.ExtraTreeClassifier()\n",
    ")\n",
    "\n",
    "scikit_bagging_classifier_models = Dict([\n",
    "    symbol(:Bagging_, key) => create_bagging_model(scikit_classifier_models[key]) \n",
    "    for key in [:DecisionTree, :ExtremyTree]]\n",
    ")\n",
    "\n",
    "scikit_boosting_classifier_models = Dict([\n",
    "    symbol(:Boosting_, key) => create_adaboost_model(scikit_classifier_models[key])\n",
    "    for key in [:DecisionTree, :ExtremyTree]]\n",
    ")\n",
    "\n",
    "scikit_ensemble_classifier_models = Dict(\n",
    "    :RandomForest => ensemble.RandomForestClassifier(n_estimators=10, max_depth=6, random_state=0),\n",
    "    :ExtraTrees   => ensemble.ExtraTreesClassifier(n_estimators=10, max_depth=6, random_state=0),\n",
    "    :GradientBoostingTrees => ensemble.GradientBoostingClassifier(n_estimators=10, learning_rate=0.5, random_state=0)\n",
    ")\n",
    "\n",
    "scikit_all_classifier_models = merge(scikit_classifier_models, \n",
    "                                     scikit_bagging_classifier_models,\n",
    "                                     scikit_boosting_classifier_models,\n",
    "                                     scikit_ensemble_classifier_models);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "render_section(\"13\", \"02\", \"Functions: Scikit Train and Predict Methods\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "render_doc(\"train_scikit_model (model, train_x, train_y)\",\n",
    "           \"\"\"Fit Scikit Model. For more information go to\n",
    "              <a scr=\"http://scikit-learn.org/\">this site</a>\"\"\",\n",
    "           [(\"model\", \"\", \"Sckit Model\"),\n",
    "            (\"train_x\", \"Array{Float,2}\", \"Feature matrix\"),\n",
    "            (\"train_y\", \"Array{Float,1}\", \"Output array\")],\n",
    "           [])\n",
    "\n",
    "render_doc(\"train_scikit_models (models, train_x, train_y)\",\n",
    "           \"\"\"Fit Scikit Models. For more information go to\n",
    "              <a scr=\"http://scikit-learn.org/\">this site</a>\"\"\",\n",
    "           [(\"models\", \"Dict\", \"A dictionary with the model name and its instance\"),\n",
    "            (\"train_x\", \"Array{Float,2}\", \"Feature matrix\"),\n",
    "            (\"train_y\", \"Array{Float,1}\", \"Output array\")],\n",
    "           [])\n",
    "\n",
    "render_doc(\"predict_scikit_model (model, X)\",\n",
    "           \"Make predicitons with Scikit model\",\n",
    "           [(\"model\", \"\", \"Scikit Model\"),\n",
    "            (\"X\", \"Array{Float,2}\", \"Feature matrix\")],\n",
    "           [(\"predictions\", \"Array\", \"A array with its predictions based on X\")])\n",
    "\n",
    "render_doc(\"predict_scikit_models (models, X)\",\n",
    "           \"Make predicitons with Scikit models\",\n",
    "           [(\"models\", \"Dict\", \"A dictionary with the model name and its instance\"),\n",
    "            (\"X\", \"Array{Float,2}\", \"Feature matrix\")],\n",
    "           [(\"predictions\", \"Dict\", \"A dictionary with the model name and its predictions based on X\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_scikit_model(model, train_x, train_y) = model[:fit](train_x, train_y)\n",
    "\n",
    "function train_scikit_models(models, train_x, train_y)\n",
    "    for (i, key) in enumerate(keys(models))\n",
    "        println(\"Training Model $key ($i/$(length(models)))...\")\n",
    "        tic(); models[key][:fit](train_x, train_y); toc()\n",
    "    end\n",
    "end\n",
    "\n",
    "predict_scikit_model(model, X) = model[:predict](X)\n",
    "\n",
    "function predict_scikit_models(models, X)\n",
    "    predictions = Dict()\n",
    "    for model_name in keys(models)\n",
    "        model = models[model_name]\n",
    "        yhat = model[:predict](X)\n",
    "        predictions[model_name] = yhat\n",
    "    end\n",
    "    return predictions\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "render_section(\"14\", \"\", \"Functions: Evaluation Metrics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "render_section(\"14\", \"01\", \"Evaluation Metrics: RMSE and Precision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "render_doc(\"eval_rmse (y, yhat)\",\n",
    "           \"Calculate Root Mean Squared Error (RMSE)\",\n",
    "           [(\"y\", \"Array{Float,1}\", \"Real output\"),\n",
    "            (\"yhat\", \"Array{Float,1}\", \"Estimated output from a model\")],\n",
    "           [(\"_\", \"Float\", \"The calculated RMSE metric\")])\n",
    "\n",
    "render_doc(\"eval_precision (y, yhat)\",\n",
    "           \"Calculate precision\",\n",
    "           [(\"y\", \"Array{Float,1}\", \"Real output\"),\n",
    "            (\"yhat\", \"Array{Float,1}\", \"Estimated output from a model\")],\n",
    "           [(\"_\", \"Float\", \"The calculated precision metric\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eval_rmse(y, yhats) = round(sqrt(sum((y - yhats) .^ 2)/length(y)), 4)\n",
    "eval_precision(y, yhats) = round(sum(Array{Int,1}(y .== yhats))/length(y), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "render_section(\"15\", \"\", \"Functions: Vowpal Wabbit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "render_doc(\"generate_vw_file (df, feature_space, label)\",\n",
    "           \"Generate from a dataframe a valid Vowpal Wabbit formatted data\",\n",
    "           [(\"df\", \"DataFrame\", \"Data that will be formatted in VW\"),\n",
    "            (\"feature_space\", \"Dict\", \"Features grouped by feature space\"),\n",
    "            (\"label\", \"Array{Int,1}\", \"Output label y\")],\n",
    "           [(\"vw_file\", \"AbstractString\", \"VW data file formatted\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VW Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "VW_LOSS_FUNCTION_SQUARED = \"squared\"\n",
    "VW_LOSS_FUNCTION_HINGE = \"hinge\"\n",
    "VW_LOSS_FUNCTION_LOGISTIC = \"logistic\"\n",
    "VW_LOSS_FUNCTION_QUANTILE = \"quantile\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "render_doc(\"\"\"train_vw_binary_classifier (\n",
    "                  vw_file_path_gzip, output_model_file_path, passes=1,\n",
    "                  quad_features=[], cubic_features=[], l1=0, l2=0,\n",
    "                  decay_learning_rate=1, initial_t=0, power_t=.5, learning_rate=.5)\"\"\",\n",
    "           \"\"\"Train a logistic regression model in Vowpal Wabbit.</br></br>\n",
    "              For more information about Vowpal Wabbit parameters go to \n",
    "              <a href=\"https://github.com/JohnLangford/vowpal_wabbit/wiki/Command-line-arguments\">\n",
    "              VW Command Line Arguments page</a>\"\"\",\n",
    "           [(\"vw_file_path_gzip\", \"AbstractString\", \"File path gziped with the train data in VW format\"),\n",
    "            (\"output_model_file_path\", \"AbstractString\", \"File path to export final model\"),\n",
    "            (\"passes\", \"Int64\", \"Number of Training Passes (Default=1)\"),\n",
    "            (\"quad_features\", \"Array{AbstactString,1}\", \"Create and use quadratic features (Default=[])\"),\n",
    "            (\"cubic_features\", \"Array{AbstactString,1}\", \"Create and use cubic features (Default=[])\"),\n",
    "            (\"l1\", \"Float64\", \"L1 regularization (Default=0)\"),\n",
    "            (\"l2\", \"Float64\", \"L2 regularization (Default=0)\"),\n",
    "            (\"decay_learning_rate\", \"Float64\", \"Set Decay factor for learning_rate between passes (Default=1)\"),\n",
    "            (\"initial_t\", \"Float64\", \"Initial t value (Default=0)\"),\n",
    "            (\"power_t\", \"Float64\", \"t power value\"),\n",
    "            (\"learning_rate\", \"Float64\", \"Set (initial) learning Rate\")],\n",
    "           [])\n",
    "\n",
    "render_doc(\"predict_vw (model_file_path, predict_file_path)\",\n",
    "           \"Predict using VW model fitted in training phase\",\n",
    "           [(\"model_file_path\", \"AbstractString\", \"File path of model fitted in VW\"),\n",
    "            (\"predict_file_path\", \"AbstractFile\", \"Path of file to predict\")],\n",
    "           [(\"results\", \"Array{Float64,1}\", \"Predicted values from the predict file\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VW Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function generate_vw_file(df, feature_space, label)\n",
    "    vw_file = \"\"\n",
    "    nrows = size(df,1)\n",
    "    features = names(df)\n",
    "    for i=1:nrows\n",
    "        vw_file *= label in features? string(df[i, label], \" \") : \"-1 \"\n",
    "        for (key, indices) in feature_space \n",
    "            start_index, end_index = indices\n",
    "            sub_features = features[start_index:end_index]\n",
    "            sub_features_names = vcat(names(df)[start_index:end_index])\n",
    "            sub_features_values = vcat(DataFrames.columns(df[i, sub_features])...)\n",
    "            sub_features = [string(sub_features_names[i], \":\", sub_features_values[i])\n",
    "                            for i=1:length(sub_features_names)]\n",
    "            vw_file *= \"|$key $(join(sub_features, ' ')) \"\n",
    "        end\n",
    "        vw_file *= \"\\n\"\n",
    "    end\n",
    "    vw_file = strip(vw_file) \n",
    "    return vw_file\n",
    "end\n",
    "\n",
    "function get_vw_general_parameters(\n",
    "    vw_file_path_gzip, output_model_file_path=\"\", passes=2, quad_features=[],\n",
    "    cubic_features=[], l1=0, l2=0, decay_learning_rate=1, \n",
    "    initial_t=0, power_t=.5, learning_rate=.5, loss_function=\"squared\")\n",
    "    cmd  = \"vw '$vw_file_path_gzip' \"\n",
    "    cmd *= !isempty(output_model_file_path)? \"-f '$output_model_file_path' \" : \"\"\n",
    "    cmd *= \"--passes $passes \"\n",
    "    cmd *= \"--cache \"\n",
    "    cmd *= \"--compressed \"\n",
    "    cmd *= length(quad_features) == 0? \"\" : join(quad_features, \" -q \")\n",
    "    cmd *= length(cubic_features) == 0? \"\" : string(join(cubic_features, \" --cubic \"), \" \")\n",
    "    cmd *= \"--bfgs \"\n",
    "    cmd *= \"--l1 $l1 \"\n",
    "    cmd *= \"--l2 $l2 \"\n",
    "    cmd *= \"--decay_learning_rate $decay_learning_rate \"\n",
    "    cmd *= \"--initial_t $initial_t \"\n",
    "    cmd *= \"--power_t $power_t \"\n",
    "    cmd *= \"--learning_rate $learning_rate \"\n",
    "    cmd *= \"--loss_function $loss_function \"\n",
    "    return cmd\n",
    "end\n",
    "\n",
    "function train_vw_binary_classifier(\n",
    "    vw_file_path_gzip, output_model_file_path=\"\"; passes=2, quad_features=[],\n",
    "    cubic_features=[], l1=0, l2=0, decay_learning_rate=1,\n",
    "    initial_t=0, power_t=.5, learning_rate=.5)\n",
    "\n",
    "    cmd = get_vw_general_parameters(vw_file_path_gzip, output_model_file_path, \n",
    "            passes, quad_features, cubic_features, l1, l2, \n",
    "            decay_learning_rate, initial_t, power_t, learning_rate,\n",
    "            VW_LOSS_FUNCTION_LOGISTIC)\n",
    "    cmd *= \"--binary\"\n",
    "    parsed_cmd = parse(\"readall(`$cmd`)\")\n",
    "    eval(parsed_cmd)\n",
    "end\n",
    "\n",
    "function predict_vw(model_file_path, predict_file_path)\n",
    "    results = readall(`vw -i $model_file_path -t $predict_file_path -p /dev/stdout --quiet`)\n",
    "    results = filter(v -> !isempty(v), split(results, \"\\n\"))\n",
    "    results = [parse(Float64, value) for value in results]\n",
    "    return results\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test VW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "export_gz(generate_vw_file(df, feature_space, label), \"test.vw\")\n",
    "train_vw_binary_classifier(\"test.vw.gz\", \"test.model\", passes=10, l1=.5)\n",
    "predict_vw(\"test.model\", \"test.vw.gz\")\n",
    "rm(\"test.vw.gz\"); rm(\"test.vw.gz.cache\"); rm(\"test.model\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "render_section(\"1X\", \"\", \"Functions: Useful Dataframes Templates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "render_doc(\"gen_dataframe_results (models_name, results, groups_name)\",\n",
    "           \"\"\"Generate a dataframe with results. It is used to store results from different models.\n",
    "              Suppose that we executed 100 models in two phases (training and validation).\n",
    "              Then we want to compare if the models are overfitting. With this structure we can store\n",
    "              data and analyzes with plots like plot_series\"\"\",\n",
    "           [(\"models_name\", \"AbstractString\", \"Models name used to obtain each result\"),\n",
    "            (\"results\", \"Array{Number,1}\", \"Results obtained with the model. Need to be aligned with the model name\"),\n",
    "            (\"groups_name\", \"Array{AbstractString}\", \"\"\"Name of the groups of results,\n",
    "              <i>e.g.</i>, [\"Train\", \"Val\"]\"\"\")],\n",
    "           [(\"df_results\", \"Dataframe\", \"Dataframe with three columns (Model, Result and Phase)\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function gen_dataframe_results(models_name, results, groups_name)\n",
    "    length(results) == 0 && error(\"Results are empty\")\n",
    "    ngroups  = length(groups_name)\n",
    "    nresults = div(length(results), ngroups)\n",
    "    models   = vcat(fill(models_name, ngroups)...)\n",
    "    groups   = repeach(groups_name, nresults)\n",
    "    df_results  = DataFrame(Model=models, Result=results, Phase=groups)\n",
    "    return df_results\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "render_section(\"1X\", \"\", \"Functions: Useful Plots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "render_doc(\"\"\"plot_series(title, dataframe, x, y, group;\n",
    "                          width=1000px, height=550px)\"\"\", \n",
    "           \"Plot series graph\", \n",
    "           [(\"title\", \"AbstractString\", \"Plot title\"),\n",
    "            (\"dataframe\", \"DataFrame\", \"Dataframe that will be used as data\"),\n",
    "            (\"x\", \"Symbol\", \"X axis label\"),\n",
    "            (\"y\", \"Symbol\", \"Y axis label\"),\n",
    "            (\"group\", \"Symbol\", \"Column used to group points by line\"),\n",
    "            (\"width\", \"px\", \"Plot width (Default=1000px)\"),\n",
    "            (\"height\", \"px\", \"Plot height (Default=550px)\")],\n",
    "           [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function plot_series(title, dataframe, x, y, group;\n",
    "                     width=1000px, height=550px)\n",
    "    set_default_plot_size(width, height)\n",
    "    plot(dataframe, x=x, y=y, color=group, Geom.point, Geom.line,\n",
    "         Scale.x_discrete, Guide.Title(title))\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.4.1-pre",
   "language": "julia",
   "name": "julia-0.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
