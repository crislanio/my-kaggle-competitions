{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<div style=\"text-align:center; display:block; float:left; padding:80px;\"><img width=\"200px\"  src=\"https://kaggle2.blob.core.windows.net/competitions/kaggle/4651/logos/front_page.png\"/><span style=\"color:red;\">**New User Booking**</span></div>\n",
    "<div style=\"\">\n",
    "**Objective:** In this recruiting competition, Airbnb challenges you to predict in which country a new user will make his or her first booking.  \n",
    "  \n",
    "** Description: ** In this challenge, you are given a list of users along with their demographics, web session records, and some summary statistics. You are asked to predict which country a new user's first booking destination will be. All the users in this dataset are from the USA.\n",
    "</div>\n",
    "<img src=\"https://kaggle2.blob.core.windows.net/competitions/kaggle/4651/media/airbnb_banner.png\" />\n",
    "\n",
    "Author: [Oliveira, D. M.](http://br.linkedin.com/in/dmoliveira)\n",
    "\n",
    "## <span style=\"color:blue\">Airbnb - New User Booking - v2 First Predictions</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Base.String is deprecated, use AbstractString instead.\n",
      "  likely near /Users/diego/.julia/v0.4/MLBase/src/modeltune.jl:5\n",
      "WARNING: Base.String is deprecated, use AbstractString instead.\n",
      "  likely near /Users/diego/.julia/v0.4/MLBase/src/modeltune.jl:5\n",
      "WARNING: Base.String is deprecated, use AbstractString instead.\n",
      "  likely near /Users/diego/.julia/v0.4/MLBase/src/modeltune.jl:5\n",
      "WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.\n",
      "  likely near /Users/diego/.julia/v0.4/MLBase/src/deprecated/datapre.jl:104\n",
      "WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.\n",
      "  likely near /Users/diego/.julia/v0.4/MLBase/src/deprecated/datapre.jl:105\n",
      "WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.\n",
      "  likely near /Users/diego/.julia/v0.4/MLBase/src/deprecated/datapre.jl:163\n",
      "WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.\n",
      "  likely near /Users/diego/.julia/v0.4/MLBase/src/deprecated/datapre.jl:163\n",
      "WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.\n",
      "  likely near /Users/diego/.julia/v0.4/MLBase/src/deprecated/datapre.jl:163\n"
     ]
    }
   ],
   "source": [
    "using DataFrames\n",
    "using MLBase\n",
    "using XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = readtable(\"data/train_v2.tsv\", separator='\\t')\n",
    "test  = readtable(\"data/test_v2.tsv\", separator='\\t')\n",
    "full  = readtable(\"data/full_v1.tsv\", separator='\\t');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Features and Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "label    = :country_destination\n",
    "labels   = Set(train[label])\n",
    "features = setdiff(names(test), [:id]);\n",
    "\n",
    "original_labels = keys(labelmap(readtable(\"data/train_users_2.csv.gz\")[label]));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "split_train_val (generic function with 1 method)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function split_train_val(df; train_size=.85, random_state=1)\n",
    "    \n",
    "    srand(random_state)\n",
    "    \n",
    "    nrows, ntraining_rows = size(df, 1), round(Int, size(df, 1) * train_size)\n",
    "    indexes               = shuffle(collect(1:nrows))\n",
    "    train                 = df[indexes[1:ntraining_rows], :]\n",
    "    validation            = df[indexes[ntraining_rows+1:end], :]\n",
    "    \n",
    "    return train, validation\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train[label]  -= 1\n",
    "X_train, X_val = split_train_val(train, train_size=.85, random_state=1)\n",
    "\n",
    "train_x = Array{Float64,2}(X_train[:, features])\n",
    "train_y = Array{Float64,1}(X_train[label])\n",
    "val_x   = Array{Float64,2}(X_val[:, features])\n",
    "val_y   = Array{Float64,1}(X_val[label])\n",
    "test_x  = Array{Float64,2}(test[:, features]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtrain  = DMatrix(train_x, label=train_y)\n",
    "dval    = DMatrix(val_x, label=val_y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Base Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[1]\ttrain-merror:0.363837\ttrain-mlogloss:1.035133\teval-merror:0.366856\teval-mlogloss:1.053807\n",
      "[2]\ttrain-merror:0.363798\ttrain-mlogloss:1.035013\teval-merror:0.366856\teval-mlogloss:1.053829\n",
      "[3]\ttrain-merror:0.363776\ttrain-mlogloss:1.034861\teval-merror:0.366856\teval-mlogloss:1.053829\n",
      "[4]\ttrain-merror:0.363864\ttrain-mlogloss:1.034734\teval-merror:0.366950\teval-mlogloss:1.053834\n",
      "[5]\ttrain-merror:0.363760\ttrain-mlogloss:1.034564\teval-merror:0.366731\teval-mlogloss:1.053845\n",
      "[6]\ttrain-merror:0.363831\ttrain-mlogloss:1.034409\teval-merror:0.366887\teval-mlogloss:1.053860\n",
      "[7]\ttrain-merror:0.363765\ttrain-mlogloss:1.034275\teval-merror:0.366731\teval-mlogloss:1.053857\n",
      "[8]\ttrain-merror:0.363771\ttrain-mlogloss:1.034145\teval-merror:0.366669\teval-mlogloss:1.053857\n",
      "[9]\ttrain-merror:0.363710\ttrain-mlogloss:1.034017\teval-merror:0.366669\teval-mlogloss:1.053882\n",
      "[10]\ttrain-merror:0.363688\ttrain-mlogloss:1.033881\teval-merror:0.366919\teval-mlogloss:1.053902\n",
      "[11]\ttrain-merror:0.363682\ttrain-mlogloss:1.033747\teval-merror:0.366762\teval-mlogloss:1.053893\n",
      "[12]\ttrain-merror:0.363638\ttrain-mlogloss:1.033599\teval-merror:0.366981\teval-mlogloss:1.053895\n",
      "[13]\ttrain-merror:0.363649\ttrain-mlogloss:1.033470\teval-merror:0.367075\teval-mlogloss:1.053919\n",
      "[14]\ttrain-merror:0.363534\ttrain-mlogloss:1.033327\teval-merror:0.367075\teval-mlogloss:1.053903\n",
      "[15]\ttrain-merror:0.363622\ttrain-mlogloss:1.033216\teval-merror:0.366856\teval-mlogloss:1.053920\n",
      "[16]\ttrain-merror:0.363627\ttrain-mlogloss:1.033075\teval-merror:0.366794\teval-mlogloss:1.053908\n",
      "[17]\ttrain-merror:0.363605\ttrain-mlogloss:1.032950\teval-merror:0.366762\teval-mlogloss:1.053946\n",
      "[18]\ttrain-merror:0.363660\ttrain-mlogloss:1.032842\teval-merror:0.366919\teval-mlogloss:1.053972\n",
      "[19]\ttrain-merror:0.363688\ttrain-mlogloss:1.032690\teval-merror:0.366887\teval-mlogloss:1.054026\n",
      "[20]\ttrain-merror:0.363721\ttrain-mlogloss:1.032545\teval-merror:0.366981\teval-mlogloss:1.054048\n",
      "[21]\ttrain-merror:0.363534\ttrain-mlogloss:1.032380\teval-merror:0.366856\teval-mlogloss:1.054001\n",
      "[22]\ttrain-merror:0.363490\ttrain-mlogloss:1.032248\teval-merror:0.367012\teval-mlogloss:1.054025\n",
      "[23]\ttrain-merror:0.363484\ttrain-mlogloss:1.032113\teval-merror:0.367012\teval-mlogloss:1.054036\n",
      "[24]\ttrain-merror:0.363468\ttrain-mlogloss:1.031971\teval-merror:0.367075\teval-mlogloss:1.054035\n",
      "[25]\ttrain-merror:0.363335\ttrain-mlogloss:1.031862\teval-merror:0.367168\teval-mlogloss:1.054050\n",
      "[26]\ttrain-merror:0.363346\ttrain-mlogloss:1.031709\teval-merror:0.367044\teval-mlogloss:1.054077\n",
      "[27]\ttrain-merror:0.363319\ttrain-mlogloss:1.031564\teval-merror:0.366919\teval-mlogloss:1.054111\n",
      "[28]\ttrain-merror:0.363280\ttrain-mlogloss:1.031439\teval-merror:0.367075\teval-mlogloss:1.054131\n",
      "[29]\ttrain-merror:0.363208\ttrain-mlogloss:1.031312\teval-merror:0.367044\teval-mlogloss:1.054163\n",
      "[30]\ttrain-merror:0.363203\ttrain-mlogloss:1.031195\teval-merror:0.367075\teval-mlogloss:1.054181\n",
      "[31]\ttrain-merror:0.363181\ttrain-mlogloss:1.031042\teval-merror:0.366856\teval-mlogloss:1.054236\n",
      "[32]\ttrain-merror:0.363208\ttrain-mlogloss:1.030953\teval-merror:0.366950\teval-mlogloss:1.054229\n",
      "[33]\ttrain-merror:0.363142\ttrain-mlogloss:1.030828\teval-merror:0.366825\teval-mlogloss:1.054237\n",
      "[34]\ttrain-merror:0.363065\ttrain-mlogloss:1.030711\teval-merror:0.366887\teval-mlogloss:1.054266\n",
      "[35]\ttrain-merror:0.363065\ttrain-mlogloss:1.030597\teval-merror:0.366731\teval-mlogloss:1.054266\n",
      "[36]\ttrain-merror:0.363159\ttrain-mlogloss:1.030461\teval-merror:0.366856\teval-mlogloss:1.054246\n",
      "[37]\ttrain-merror:0.363098\ttrain-mlogloss:1.030306\teval-merror:0.366981\teval-mlogloss:1.054268\n",
      "[38]\ttrain-merror:0.363109\ttrain-mlogloss:1.030172\teval-merror:0.367075\teval-mlogloss:1.054263\n",
      "[39]\ttrain-merror:0.363043\ttrain-mlogloss:1.030009\teval-merror:0.367012\teval-mlogloss:1.054280\n",
      "[40]\ttrain-merror:0.363021\ttrain-mlogloss:1.029894\teval-merror:0.366887\teval-mlogloss:1.054287\n",
      "[41]\ttrain-merror:0.362889\ttrain-mlogloss:1.029732\teval-merror:0.366981\teval-mlogloss:1.054307\n",
      "[42]\ttrain-merror:0.362768\ttrain-mlogloss:1.029606\teval-merror:0.367012\teval-mlogloss:1.054328\n",
      "[43]\ttrain-merror:0.362795\ttrain-mlogloss:1.029493\teval-merror:0.366856\teval-mlogloss:1.054385\n",
      "[44]\ttrain-merror:0.362756\ttrain-mlogloss:1.029346\teval-merror:0.366825\teval-mlogloss:1.054421\n",
      "[45]\ttrain-merror:0.362773\ttrain-mlogloss:1.029214\teval-merror:0.367044\teval-mlogloss:1.054483\n",
      "[46]\ttrain-merror:0.362795\ttrain-mlogloss:1.029085\teval-merror:0.366887\teval-mlogloss:1.054470\n",
      "[47]\ttrain-merror:0.362723\ttrain-mlogloss:1.028953\teval-merror:0.367012\teval-mlogloss:1.054446\n",
      "[48]\ttrain-merror:0.362740\ttrain-mlogloss:1.028847\teval-merror:0.366919\teval-mlogloss:1.054478\n",
      "[49]\ttrain-merror:0.362586\ttrain-mlogloss:1.028730\teval-merror:0.366887\teval-mlogloss:1.054533\n",
      "[50]\ttrain-merror:0.362613\ttrain-mlogloss:1.028609\teval-merror:0.366794\teval-mlogloss:1.054585\n",
      "[51]\ttrain-merror:0.362580\ttrain-mlogloss:1.028473\teval-merror:0.366731\teval-mlogloss:1.054592\n",
      "[52]\ttrain-merror:0.362602\ttrain-mlogloss:1.028319\teval-merror:0.366825\teval-mlogloss:1.054567\n",
      "[53]\ttrain-merror:0.362619\ttrain-mlogloss:1.028210\teval-merror:0.366981\teval-mlogloss:1.054606\n",
      "[54]\ttrain-merror:0.362657\ttrain-mlogloss:1.028105\teval-merror:0.367012\teval-mlogloss:1.054634\n",
      "[55]\ttrain-merror:0.362597\ttrain-mlogloss:1.027979\teval-merror:0.366950\teval-mlogloss:1.054654\n",
      "[56]\ttrain-merror:0.362553\ttrain-mlogloss:1.027851\teval-merror:0.366919\teval-mlogloss:1.054662\n",
      "[57]\ttrain-merror:0.362531\ttrain-mlogloss:1.027726\teval-merror:0.366856\teval-mlogloss:1.054655\n",
      "[58]\ttrain-merror:0.362668\ttrain-mlogloss:1.027614\teval-merror:0.366700\teval-mlogloss:1.054675\n",
      "[59]\ttrain-merror:0.362575\ttrain-mlogloss:1.027500\teval-merror:0.366887\teval-mlogloss:1.054696\n",
      "[60]\ttrain-merror:0.362475\ttrain-mlogloss:1.027380\teval-merror:0.366762\teval-mlogloss:1.054741\n",
      "[61]\ttrain-merror:0.362486\ttrain-mlogloss:1.027275\teval-merror:0.366731\teval-mlogloss:1.054787\n",
      "[62]\ttrain-merror:0.362365\ttrain-mlogloss:1.027163\teval-merror:0.366856\teval-mlogloss:1.054851\n",
      "[63]\ttrain-merror:0.362305\ttrain-mlogloss:1.027022\teval-merror:0.366575\teval-mlogloss:1.054861\n",
      "[64]\ttrain-merror:0.362338\ttrain-mlogloss:1.026901\teval-merror:0.366575\teval-mlogloss:1.054860\n",
      "[65]\ttrain-merror:0.362227\ttrain-mlogloss:1.026754\teval-merror:0.366669\teval-mlogloss:1.054853\n",
      "[66]\ttrain-merror:0.362167\ttrain-mlogloss:1.026651\teval-merror:0.366450\teval-mlogloss:1.054846\n",
      "[67]\ttrain-merror:0.362150\ttrain-mlogloss:1.026556\teval-merror:0.366356\teval-mlogloss:1.054863\n",
      "[68]\ttrain-merror:0.362156\ttrain-mlogloss:1.026406\teval-merror:0.366356\teval-mlogloss:1.054836\n",
      "[69]\ttrain-merror:0.362101\ttrain-mlogloss:1.026280\teval-merror:0.366325\teval-mlogloss:1.054840\n",
      "[70]\ttrain-merror:0.362112\ttrain-mlogloss:1.026142\teval-merror:0.366294\teval-mlogloss:1.054934\n",
      "[71]\ttrain-merror:0.362123\ttrain-mlogloss:1.026016\teval-merror:0.366075\teval-mlogloss:1.054959\n",
      "[72]\ttrain-merror:0.362117\ttrain-mlogloss:1.025890\teval-merror:0.366044\teval-mlogloss:1.054968\n",
      "[73]\ttrain-merror:0.362051\ttrain-mlogloss:1.025769\teval-merror:0.366075\teval-mlogloss:1.054993\n",
      "[74]\ttrain-merror:0.362068\ttrain-mlogloss:1.025664\teval-merror:0.365919\teval-mlogloss:1.054983\n",
      "[75]\ttrain-merror:0.362045\ttrain-mlogloss:1.025550\teval-merror:0.365732\teval-mlogloss:1.054944\n",
      "[76]\ttrain-merror:0.362045\ttrain-mlogloss:1.025447\teval-merror:0.365544\teval-mlogloss:1.054967\n",
      "[77]\ttrain-merror:0.362029\ttrain-mlogloss:1.025313\teval-merror:0.365576\teval-mlogloss:1.054965\n",
      "[78]\ttrain-merror:0.362051\ttrain-mlogloss:1.025200\teval-merror:0.365607\teval-mlogloss:1.054985\n",
      "[79]\ttrain-merror:0.361963\ttrain-mlogloss:1.025056\teval-merror:0.365763\teval-mlogloss:1.054991\n",
      "[80]\ttrain-merror:0.361963\ttrain-mlogloss:1.024940\teval-merror:0.365825\teval-mlogloss:1.054988\n",
      "[81]\ttrain-merror:0.361935\ttrain-mlogloss:1.024824\teval-merror:0.366107\teval-mlogloss:1.054996\n",
      "[82]\ttrain-merror:0.362012\ttrain-mlogloss:1.024707\teval-merror:0.366200\teval-mlogloss:1.055028\n",
      "[83]\ttrain-merror:0.362012\ttrain-mlogloss:1.024572\teval-merror:0.366232\teval-mlogloss:1.055028\n",
      "[84]\ttrain-merror:0.361990\ttrain-mlogloss:1.024451\teval-merror:0.366200\teval-mlogloss:1.055052\n",
      "[85]\ttrain-merror:0.361957\ttrain-mlogloss:1.024341\teval-merror:0.366169\teval-mlogloss:1.055076\n",
      "[86]\ttrain-merror:0.361985\ttrain-mlogloss:1.024219\teval-merror:0.366075\teval-mlogloss:1.055093\n",
      "[87]\ttrain-merror:0.361952\ttrain-mlogloss:1.024122\teval-merror:0.366075\teval-mlogloss:1.055119\n",
      "[88]\ttrain-merror:0.361897\ttrain-mlogloss:1.024019\teval-merror:0.366169\teval-mlogloss:1.055148\n",
      "[89]\ttrain-merror:0.361853\ttrain-mlogloss:1.023900\teval-merror:0.366169\teval-mlogloss:1.055153\n",
      "[90]\ttrain-merror:0.361880\ttrain-mlogloss:1.023776\teval-merror:0.366232\teval-mlogloss:1.055153\n",
      "[91]\ttrain-merror:0.361924\ttrain-mlogloss:1.023675\teval-merror:0.366232\teval-mlogloss:1.055168\n",
      "[92]\ttrain-merror:0.361902\ttrain-mlogloss:1.023547\teval-merror:0.365950\teval-mlogloss:1.055155\n",
      "[93]\ttrain-merror:0.361869\ttrain-mlogloss:1.023450\teval-merror:0.366107\teval-mlogloss:1.055171\n",
      "[94]\ttrain-merror:0.361814\ttrain-mlogloss:1.023342\teval-merror:0.366107\teval-mlogloss:1.055166\n",
      "[95]\ttrain-merror:0.361753\ttrain-mlogloss:1.023234\teval-merror:0.366263\teval-mlogloss:1.055173\n",
      "[96]\ttrain-merror:0.361759\ttrain-mlogloss:1.023106\teval-merror:0.366232\teval-mlogloss:1.055172\n",
      "[97]\ttrain-merror:0.361731\ttrain-mlogloss:1.022996\teval-merror:0.366388\teval-mlogloss:1.055174\n",
      "[98]\ttrain-merror:0.361803\ttrain-mlogloss:1.022896\teval-merror:0.366419\teval-mlogloss:1.055181\n",
      "[99]\ttrain-merror:0.361720\ttrain-mlogloss:1.022783\teval-merror:0.366481\teval-mlogloss:1.055208\n",
      "[100]\ttrain-merror:0.361704\ttrain-mlogloss:1.022651\teval-merror:0.366388\teval-mlogloss:1.055237\n",
      "[101]\ttrain-merror:0.361671\ttrain-mlogloss:1.022531\teval-merror:0.366388\teval-mlogloss:1.055261\n",
      "[102]\ttrain-merror:0.361555\ttrain-mlogloss:1.022431\teval-merror:0.366200\teval-mlogloss:1.055267\n",
      "[103]\ttrain-merror:0.361500\ttrain-mlogloss:1.022305\teval-merror:0.366200\teval-mlogloss:1.055254\n",
      "[104]\ttrain-merror:0.361511\ttrain-mlogloss:1.022174\teval-merror:0.365982\teval-mlogloss:1.055297\n",
      "[105]\ttrain-merror:0.361494\ttrain-mlogloss:1.022103\teval-merror:0.365950\teval-mlogloss:1.055300\n",
      "[106]\ttrain-merror:0.361428\ttrain-mlogloss:1.022000\teval-merror:0.365888\teval-mlogloss:1.055332\n",
      "[107]\ttrain-merror:0.361423\ttrain-mlogloss:1.021878\teval-merror:0.365825\teval-mlogloss:1.055358\n",
      "[108]\ttrain-merror:0.361456\ttrain-mlogloss:1.021775\teval-merror:0.365888\teval-mlogloss:1.055351\n",
      "[109]\ttrain-merror:0.361483\ttrain-mlogloss:1.021664\teval-merror:0.365950\teval-mlogloss:1.055348\n",
      "[110]\ttrain-merror:0.361428\ttrain-mlogloss:1.021562\teval-merror:0.366013\teval-mlogloss:1.055391\n",
      "[111]\ttrain-merror:0.361395\ttrain-mlogloss:1.021439\teval-merror:0.366107\teval-mlogloss:1.055388\n",
      "[112]\ttrain-merror:0.361368\ttrain-mlogloss:1.021324\teval-merror:0.366169\teval-mlogloss:1.055394\n",
      "[113]\ttrain-merror:0.361345\ttrain-mlogloss:1.021223\teval-merror:0.366044\teval-mlogloss:1.055424\n",
      "[114]\ttrain-merror:0.361384\ttrain-mlogloss:1.021119\teval-merror:0.366044\teval-mlogloss:1.055446\n",
      "[115]\ttrain-merror:0.361357\ttrain-mlogloss:1.021015\teval-merror:0.366013\teval-mlogloss:1.055497\n",
      "[116]\ttrain-merror:0.361345\ttrain-mlogloss:1.020912\teval-merror:0.366107\teval-mlogloss:1.055542\n",
      "[117]\ttrain-merror:0.361318\ttrain-mlogloss:1.020822\teval-merror:0.366107\teval-mlogloss:1.055558\n",
      "[118]\ttrain-merror:0.361373\ttrain-mlogloss:1.020701\teval-merror:0.366075\teval-mlogloss:1.055554\n",
      "[119]\ttrain-merror:0.361274\ttrain-mlogloss:1.020595\teval-merror:0.366138\teval-mlogloss:1.055578\n",
      "[120]\ttrain-merror:0.361279\ttrain-mlogloss:1.020500\teval-merror:0.366013\teval-mlogloss:1.055592\n",
      "[121]\ttrain-merror:0.361318\ttrain-mlogloss:1.020410\teval-merror:0.365950\teval-mlogloss:1.055624\n",
      "[122]\ttrain-merror:0.361307\ttrain-mlogloss:1.020310\teval-merror:0.366075\teval-mlogloss:1.055626\n",
      "[123]\ttrain-merror:0.361219\ttrain-mlogloss:1.020212\teval-merror:0.365919\teval-mlogloss:1.055640\n",
      "[124]\ttrain-merror:0.361164\ttrain-mlogloss:1.020108\teval-merror:0.365888\teval-mlogloss:1.055655\n",
      "[125]\ttrain-merror:0.361064\ttrain-mlogloss:1.020015\teval-merror:0.365825\teval-mlogloss:1.055661\n",
      "[126]\ttrain-merror:0.361109\ttrain-mlogloss:1.019895\teval-merror:0.365919\teval-mlogloss:1.055683\n",
      "[127]\ttrain-merror:0.361053\ttrain-mlogloss:1.019794\teval-merror:0.365794\teval-mlogloss:1.055722\n",
      "[128]\ttrain-merror:0.361086\ttrain-mlogloss:1.019699\teval-merror:0.365701\teval-mlogloss:1.055753\n",
      "[129]\ttrain-merror:0.361015\ttrain-mlogloss:1.019590\teval-merror:0.365607\teval-mlogloss:1.055744\n",
      "[130]\ttrain-merror:0.361026\ttrain-mlogloss:1.019498\teval-merror:0.365544\teval-mlogloss:1.055779\n",
      "[131]\ttrain-merror:0.361070\ttrain-mlogloss:1.019386\teval-merror:0.365825\teval-mlogloss:1.055799\n",
      "[132]\ttrain-merror:0.361004\ttrain-mlogloss:1.019291\teval-merror:0.365857\teval-mlogloss:1.055817\n",
      "[133]\ttrain-merror:0.360949\ttrain-mlogloss:1.019205\teval-merror:0.365794\teval-mlogloss:1.055858\n",
      "[134]\ttrain-merror:0.360789\ttrain-mlogloss:1.019106\teval-merror:0.365950\teval-mlogloss:1.055905\n",
      "[135]\ttrain-merror:0.360778\ttrain-mlogloss:1.018991\teval-merror:0.365950\teval-mlogloss:1.055907\n",
      "[136]\ttrain-merror:0.360767\ttrain-mlogloss:1.018893\teval-merror:0.366013\teval-mlogloss:1.055903\n",
      "[137]\ttrain-merror:0.360811\ttrain-mlogloss:1.018784\teval-merror:0.365825\teval-mlogloss:1.055921\n",
      "[138]\ttrain-merror:0.360827\ttrain-mlogloss:1.018680\teval-merror:0.365763\teval-mlogloss:1.055915\n",
      "[139]\ttrain-merror:0.360783\ttrain-mlogloss:1.018579\teval-merror:0.365763\teval-mlogloss:1.055955\n",
      "[140]\ttrain-merror:0.360629\ttrain-mlogloss:1.018446\teval-merror:0.365794\teval-mlogloss:1.056031\n",
      "[141]\ttrain-merror:0.360640\ttrain-mlogloss:1.018325\teval-merror:0.365794\teval-mlogloss:1.056073\n",
      "[142]\ttrain-merror:0.360596\ttrain-mlogloss:1.018213\teval-merror:0.365857\teval-mlogloss:1.056097\n",
      "[143]\ttrain-merror:0.360690\ttrain-mlogloss:1.018137\teval-merror:0.366013\teval-mlogloss:1.056122\n",
      "[144]\ttrain-merror:0.360679\ttrain-mlogloss:1.018041\teval-merror:0.365794\teval-mlogloss:1.056157\n",
      "[145]\ttrain-merror:0.360651\ttrain-mlogloss:1.017940\teval-merror:0.365982\teval-mlogloss:1.056147\n",
      "[146]\ttrain-merror:0.360607\ttrain-mlogloss:1.017828\teval-merror:0.365701\teval-mlogloss:1.056180\n",
      "[147]\ttrain-merror:0.360574\ttrain-mlogloss:1.017704\teval-merror:0.365732\teval-mlogloss:1.056231\n",
      "[148]\ttrain-merror:0.360535\ttrain-mlogloss:1.017608\teval-merror:0.365701\teval-mlogloss:1.056285\n",
      "[149]\ttrain-merror:0.360519\ttrain-mlogloss:1.017520\teval-merror:0.365607\teval-mlogloss:1.056303\n",
      "[150]\ttrain-merror:0.360497\ttrain-mlogloss:1.017402\teval-merror:0.365950\teval-mlogloss:1.056323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 736"
     ]
    },
    {
     "data": {
      "text/plain": [
       "736.385461367"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_rounds = 150\n",
    "watchlist  = [(dtrain, \"train\"), (dval, \"eval\")]\n",
    "metrics    = [\"merror\", \"mlogloss\"]\n",
    "params     = Dict(\"objective\"         => \"multi:softprob\",\n",
    "                   \"booster\"          => \"gbtree\",\n",
    "                   \"eta\"              => .1,\n",
    "                   \"alpha\"            => .5,\n",
    "                   \"gamma\"            => .0,\n",
    "                   \"max_depth\"        =>  5,\n",
    "                   \"colsample_bytree\" => .5,\n",
    "                   \"min_child_weight\" =>  10,\n",
    "                   \"subsample\"        => .5,\n",
    "                   \"seed\"             =>  1)\n",
    "\n",
    "println(\"Training Base Model...\")\n",
    "tic()\n",
    "model      = XGBoost.xgboost(dtrain, num_rounds, param=params, metrics=metrics,\n",
    "                             num_class=length(labels), watchlist=watchlist)\n",
    "toc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_top_n (generic function with 1 method)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function get_top_n(prob_matrix, n)\n",
    "    \n",
    "    top_n_list   = Array[]\n",
    "    nrows, ncols = size(prob_matrix)\n",
    "    n            = min(ncols, n)\n",
    "    \n",
    "    for i=1:nrows\n",
    "        \n",
    "        tuple_list = [(j, prob_matrix[i, j]) for j=1:ncols]\n",
    "        top_n      = sort(tuple_list, by = x -> last(x), rev=true)[1:n]\n",
    "        top_n      = [first(x) for x in top_n]\n",
    "        \n",
    "        push!(top_n_list, top_n)\n",
    "    end\n",
    "    \n",
    "    return top_n_list\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Train & Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prepare_dataframe_submission (generic function with 3 methods)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function eval_map_precision_at_n(y, yhats; at_n=5)\n",
    "    total, map_hit, precision_hit = 0, 0, 0\n",
    "    by(yhats, :id) do df\n",
    "        index = findfirst(df[:country], y[df[1, :id]]) - 1\n",
    "        index >= 0 && (map_hit += (at_n - index)/at_n; precision_hit += 1)\n",
    "        total += 1\n",
    "    end\n",
    "    return round(map_hit/total, 4), round(precision_hit/total, 4)\n",
    "end\n",
    "\n",
    "function evaluate_at_n(ids, labels, data; at_n=5)\n",
    "    nrows = size(data, 1)\n",
    "    y = Dict([ids[i] => original_labels[labels[i] + 1] for i=1:nrows])\n",
    "    yhats = XGBoost.predict(model, data)\n",
    "    yhats = reshape(yhats, length(original_labels), nrows)'\n",
    "    yhats_top_n = prepare_dataframe_submission(ids, get_top_n(yhats, at_n), at_n=at_n)\n",
    "    eval_map_precision_at_n(y, yhats_top_n)\n",
    "end\n",
    "\n",
    "function prepare_dataframe_submission(ids, yhats_top_n; at_n=5)\n",
    "    \n",
    "    ids_repeated  = repeach(ids, at_n)\n",
    "    new_yhats     = [ original_labels[yhat] for yhat in vcat(yhats_top_n...) ]\n",
    "    submission_df = DataFrame(id=ids_repeated, country=new_yhats)\n",
    "    \n",
    "    return submission_df\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0856,0.0856)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_at_n(X_train[:id], X_train[label], train_x, at_n=5)\n",
    "evaluate_at_n(X_train[:id], X_train[label], train_x, at_n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0617,0.0617)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_at_n(X_val[:id], X_val[label], val_x, at_n=5)\n",
    "evaluate_at_n(X_val[:id], X_val[label], val_x, at_n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yhats = XGBoost.predict(model, test_x)\n",
    "yhats = reshape(yhats, length(original_labels), size(test_x, 1))';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yhats_top_n = get_top_n(yhats, 5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission_df = prepare_dataframe_submission(test[:id], yhats, yhats_top_n);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "writetable(\"data/submissions/submission_v7_ds2_xgboost_msoftprob_gbtree_eta05_md5_ss3_alpha5_csb5_mcw10_nr150.csv\", submission_df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kagle Scores from Submited Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Score: <span style=\"color:blue;\">0.86389</span> [v7]\n",
    "\n",
    "- v7 **XGB** (DS2 MSoftProb GBTree Eta.05 MD 6 SS.5 NR150 $\\alpha$5 CSB5 MCW10): **0.86389** tme:.367\ttmll:1.05 eme:.367\temll:1.06 (map/p@5: (0.8704,0.9667), (0.8685,0.9607))\n",
    "- v6 **XGB** (DS2 MSoftProb GBTree Eta.3 MD 6 SS.5 NR100 $\\alpha$5 CSB5 MCW10): **0.86359** tme.364 tmll1.04 eme.366 emll1.05   \n",
    "- v4 **XGB** (DS1 MSoftProb GBTree Eta.3 MD 6 SS.5 NR100 $\\alpha$5 CSB5 MCW10): **0.86109** tme.360 tmll1.02 eme.369 emll1.064   \n",
    "- v3 **XGB** (DS1 MSoftMax GBTree Eta.3 MD 6 SS.5 NR100 $\\alpha$5 CSB5 MCW10): **0.70496** tme 0.358 tmll 1.019 eme 0.366 emll1.061  \n",
    "- v2 **XGB** (DS1 MSoftMax GBTree Eta.7 MD 5 SS.85 NR2000): ** 0.65697** tme.181 tmll.499 eme.403 emll1.477\n",
    "- v1 **XGB** (DS1 MSoftMax GBTree Eta.7 MD 5 SS.85 NR100): **0.70174** tme.349 tmll.948 eme.367 emll1.077"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.4.1-pre",
   "language": "julia",
   "name": "julia-0.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
